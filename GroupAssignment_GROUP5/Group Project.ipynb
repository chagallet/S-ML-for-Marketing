{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# InClass Kaggle Competition - Group 5 \n",
    "\n",
    "This notebook shows the implementation of machine learning pipeline for the InClass Kaggle Competition.\n",
    "\n",
    "Group Members:\n",
    "- Charlotte Gallet\n",
    "- Elina Kelly\n",
    "- Hina Hussain\n",
    "\n",
    "Submitted on: 10/04/2022\n",
    "\n",
    "---\n",
    "\n",
    "The machine learning pipeline includes:\n",
    "\n",
    "1. Data processing (Part 2)\n",
    "- [x] Error correction\n",
    "- [x] Feature engineering\n",
    "- [x] Value transformation\n",
    "- [x] Value representation\n",
    "- [x] Variable selection\n",
    "\n",
    "2. Modeling (Part 3)\n",
    "- [x] Benchmarking 7 models\n",
    "- [x] Hyper parameter tuning\n",
    "\n",
    "4. Interpretation (Part 3)\n",
    "- [x] Learning curve\n",
    "- [x] Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "###################################################################\n",
    "# MODIFY THESE FLAGS TO TURN ON/OFF THE DATA PROCESSING FUNCTIONS #\n",
    "###################################################################\n",
    "\n",
    "# Flag variables to run the data processing steps\n",
    "# Feature engineering step\n",
    "enable_num_poly = True  # Add polynomial terms\n",
    "# Value transformation step\n",
    "enable_trans_cat_dt = True  # Remapping cat variables - Decision tree–based remapping\n",
    "enable_trans_num_dt = True  # Discretizing num variables - Decision tree–based discretization\n",
    "#enable_trans_num_ef = True  # Discretizing num variables - Equal frequency discretization\n",
    "#enable_trans_num_ew = True  # Discretizing num variables - Equal width discretization\n",
    "# Value representation step\n",
    "enable_repr_dummy = True  # Represent cat variables - Dummy coding\n",
    "#enable_repr_icd = True  # Represent cat variables - Incidence (of target variable) replacement\n",
    "#enable_repr_woe = True  # Represent cat variables - Weight-of-Evidence (WoE) conversion\n",
    "drop_cat_vars = True  # Drop cat variables after value representation step\n",
    "# Other data processing\n",
    "#enable_normalize = True  # Normalize the data to the same range [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data exploration\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data processing\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Experimental setup\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_validate, GridSearchCV\n",
    "#from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Read and print out some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 241 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read train, test\n",
    "train = pd.read_csv(\"C:/Users/hhussain1/Desktop/SML/Group Project/Data/bank_mkt_train.csv\", low_memory=False)\n",
    "test = pd.read_csv(\"C:/Users/hhussain1/Desktop/SML/Group Project/Data/bank_mkt_test.csv\", low_memory=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     10\n",
      "float64     9\n",
      "int64       2\n",
      "dtype: int64\n",
      "Wall time: 7 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>subscribe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29925</td>\n",
       "      <td>42.0</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.968</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37529</td>\n",
       "      <td>35.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.960</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2757</td>\n",
       "      <td>44.0</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>92.893</td>\n",
       "      <td>-46.2</td>\n",
       "      <td>1.264</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642</td>\n",
       "      <td>45.0</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.453</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14183</td>\n",
       "      <td>45.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.859</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id   age         job  marital          education  default  housing  \\\n",
       "0      29925  42.0  management  married           basic.9y       no       no   \n",
       "1      37529  35.0  unemployed  married  university.degree       no      yes   \n",
       "2       2757  44.0  technician  married           basic.9y       no      yes   \n",
       "3       9642  45.0    services  married        high.school       no      yes   \n",
       "4      14183  45.0     unknown  married            unknown  unknown  unknown   \n",
       "\n",
       "      loan    contact month  ... campaign  pdays  previous     poutcome  \\\n",
       "0       no   cellular   jul  ...      1.0  999.0       0.0  nonexistent   \n",
       "1       no  telephone   jun  ...      4.0  999.0       0.0  nonexistent   \n",
       "2      yes   cellular   may  ...      1.0  999.0       0.0  nonexistent   \n",
       "3       no   cellular   apr  ...      1.0  999.0       0.0  nonexistent   \n",
       "4  unknown  telephone   may  ...      1.0  999.0       0.0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \\\n",
       "0          1.4          93.918          -42.7      4.968       5228.1   \n",
       "1          1.4          94.465          -41.8      4.960       5228.1   \n",
       "2         -1.8          92.893          -46.2      1.264       5099.1   \n",
       "3         -1.8          93.075          -47.1      1.453       5099.1   \n",
       "4          1.1          93.994          -36.4      4.859       5191.0   \n",
       "\n",
       "   subscribe  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Print out to check the data\n",
    "print(train.dtypes.value_counts())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Create a list of column names to manage variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# General list of variables\n",
    "id_var = [\"client_id\"]  # ID\n",
    "target_var = [\"subscribe\"]  # Target get variable\n",
    "predictors = [v for v in train.columns if v not in id_var + target_var]\n",
    "\n",
    "# List of numerical and catergorical variables\n",
    "num_vars = ['age', 'campaign', 'pdays', 'previous',\n",
    "            'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "cat_vars = ['job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "            'contact', 'month', 'day_of_week',\n",
    "            'poutcome']\n",
    "\n",
    "# Double check the list of variables\n",
    "assert(len(predictors) == len(num_vars) + len(cat_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Check the target variable class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subscribe\n",
      "0            17729\n",
      "1             2271\n",
      "dtype: int64\n",
      "subscribe\n",
      "0            0.88645\n",
      "1            0.11355\n",
      "dtype: float64\n",
      "Wall time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# By number\n",
    "print(train[target_var].value_counts())\n",
    "\n",
    "# By percentage\n",
    "print(train[target_var].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Creating a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the train set into train and validation\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train[train.columns[~train.columns.isin(['subscribe'])]], train[\"subscribe\"], test_size=0.2, stratify = train[\"subscribe\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final validation set with IV and DV\n",
    "validation = X_val\n",
    "validation[\"subscribe\"] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final train set\n",
    "train = X_train\n",
    "train[\"subscribe\"] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "validation = validation.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 21)\n",
      "(4000, 21)\n",
      "(10000, 20)\n"
     ]
    }
   ],
   "source": [
    "#Check dimensions\n",
    "print(train.shape)\n",
    "print(validation.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Error, data correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Check and correct data error - Constant variables\n",
    "\n",
    "Constant variables on train do not contain information and may cause data processing or model training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop constant variable: []\n",
      "Wall time: 40 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Count number of unique values of each variable\n",
    "vars_nunique = train[num_vars + cat_vars].apply(pd.Series.nunique, dropna=False, axis=0)\n",
    "cont_vars = vars_nunique.index[vars_nunique < 2].tolist()\n",
    "print(\"Drop constant variable:\", cont_vars)\n",
    "\n",
    "# Correct variable list\n",
    "num_vars = [v for v in num_vars if v not in cont_vars]\n",
    "cat_vars = [v for v in cat_vars if v not in cont_vars]\n",
    "\n",
    "# Update train, validation, test\n",
    "train = train[id_var + num_vars + cat_vars + target_var]\n",
    "validation = validation[id_var + num_vars + cat_vars + target_var]\n",
    "test = test[id_var + num_vars + cat_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Check and correct data error - Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - # NA of num vars: 1378\n",
      "Train - # NA of cat vars: 1531\n",
      "Validation - # NA of num vars: 352\n",
      "Validation - # NA of cat vars: 403\n",
      "Test - # NA of num vars: 918\n",
      "Test - # NA of cat vars: 1057\n",
      "Wall time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Check missing value\n",
    "print('Train - # NA of num vars:', train[num_vars].isna().sum().sum())\n",
    "print('Train - # NA of cat vars:', train[cat_vars].isna().sum().sum())\n",
    "print('Validation - # NA of num vars:', validation[num_vars].isna().sum().sum())\n",
    "print('Validation - # NA of cat vars:', validation[cat_vars].isna().sum().sum())\n",
    "print('Test - # NA of num vars:', test[num_vars].isna().sum().sum())\n",
    "print('Test - # NA of cat vars:', test[cat_vars].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop num variables with high missing pct: []\n",
      "Drop cat variables with high missing pct: []\n",
      "Wall time: 21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here, we test the effect of dropping variables with high missing percentage (>30%)\n",
    "na_threshold = 0.3\n",
    "\n",
    "# Drop num variables with more than 30% missing values\n",
    "num_na_pct = train[num_vars].isnull().mean()\n",
    "num_vars = num_na_pct[num_na_pct <= na_threshold].index.tolist()\n",
    "print(\"Drop num variables with high missing pct:\", num_na_pct[num_na_pct > na_threshold].tolist())\n",
    "\n",
    "# Drop cat variables with more than 30% missing values\n",
    "cat_na_pct = train[cat_vars].isnull().mean()\n",
    "cat_vars = cat_na_pct[cat_na_pct <= 0.3].index.tolist()\n",
    "print(\"Drop cat variables with high missing pct:\", cat_na_pct[cat_na_pct > na_threshold].tolist())\n",
    "\n",
    "# Update train, test\n",
    "train = train[id_var + num_vars + cat_vars + target_var]\n",
    "validation = validation[id_var + num_vars + cat_vars + target_var]\n",
    "test = test[id_var + num_vars + cat_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# List summary variables to track missing values imputation\n",
    "na_vars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Numerical variables\n",
    "# Build the missing value imputor using the mean\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean', add_indicator=True)\n",
    "imp.fit(train[num_vars])\n",
    "\n",
    "# Reconstruct the list of vars + indicators\n",
    "na_vars = na_vars + [num_vars[v] + \"_na\" for v in imp.indicator_.features_]\n",
    "impute_vars = num_vars + na_vars\n",
    "\n",
    "# Apply on train, validation, test\n",
    "train[impute_vars] = pd.DataFrame(imp.transform(train[num_vars]), columns=impute_vars)\n",
    "validation[impute_vars] = pd.DataFrame(imp.transform(validation[num_vars]), columns=impute_vars)\n",
    "test[impute_vars] = pd.DataFrame(imp.transform(test[num_vars]), columns=impute_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>...</th>\n",
       "      <th>subscribe</th>\n",
       "      <th>age_na</th>\n",
       "      <th>campaign_na</th>\n",
       "      <th>pdays_na</th>\n",
       "      <th>previous_na</th>\n",
       "      <th>emp.var.rate_na</th>\n",
       "      <th>cons.price.idx_na</th>\n",
       "      <th>cons.conf.idx_na</th>\n",
       "      <th>euribor3m_na</th>\n",
       "      <th>nr.employed_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21641</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35922</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id   age  campaign  pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0      21641  36.0       2.0  999.0       0.0           1.1          93.994   \n",
       "1      35922  26.0       1.0  999.0       0.0           1.4          94.465   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed  ... subscribe age_na campaign_na  \\\n",
       "0          -36.4      4.857       5191.0  ...         0    0.0         0.0   \n",
       "1          -41.8      4.962       5228.1  ...         0    0.0         0.0   \n",
       "\n",
       "  pdays_na previous_na emp.var.rate_na cons.price.idx_na cons.conf.idx_na  \\\n",
       "0      0.0         0.0             0.0               0.0              0.0   \n",
       "1      0.0         0.0             0.0               0.0              0.0   \n",
       "\n",
       "  euribor3m_na nr.employed_na  \n",
       "0          0.0            0.0  \n",
       "1          0.0            0.0  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Categorical variables\n",
    "# Impute missing value using a new category \"Missing\"\n",
    "# Note: If the categorical vars are imputed by most_frequent, the indicators should be added\n",
    "train[cat_vars] = train[cat_vars].fillna('Missing')\n",
    "validation[cat_vars] = validation[cat_vars].fillna('Missing')\n",
    "test[cat_vars] = test[cat_vars].fillna('Missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Check and correct data error - Outliers in numerical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age has # outliers on train, validation, test : 144 [ 0.9 % ] 37 [ 0.92 % ] 89 [ 0.89 % ]\n",
      "campaign has # outliers on train, validation, test : 341 [ 2.13 % ] 82 [ 2.05 % ] 210 [ 2.1 % ]\n",
      "pdays has # outliers on train, validation, test : 596 [ 3.72 % ] 154 [ 3.85 % ] 371 [ 3.71 % ]\n",
      "previous has # outliers on train, validation, test : 416 [ 2.6 % ] 103 [ 2.58 % ] 269 [ 2.69 % ]\n",
      "Wall time: 32 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Check the outliers on train, validation, test\n",
    "for v in num_vars:\n",
    "    # Calculate the boundaries on train [mean-3*sd, mean+3*sd]\n",
    "    mu = np.mean(train[v])\n",
    "    sd = np.std(train[v])\n",
    "    lower = mu - 3*sd\n",
    "    upper = mu + 3*sd\n",
    "    # Check outliers using the boundaries\n",
    "    train_out = (train[v] < lower) | (train[v] > upper)\n",
    "    validation_out = (validation[v] < lower) | (validation[v] > upper)\n",
    "    test_out = (test[v] < lower) | (test[v] > upper)\n",
    "    if np.sum(train_out) + np.sum(validation_out) +  np.sum(test_out) > 0:\n",
    "        print(v, \"has # outliers on train, validation, test :\",\n",
    "              np.sum(train_out), \"[\", np.round(100*np.mean(train_out), 2), \"% ]\",\n",
    "              np.sum(validation_out), \"[\", np.round(100*np.mean(validation_out), 2), \"% ]\",\n",
    "              np.sum(test_out), \"[\", np.round(100*np.mean(test_out), 2), \"% ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Looking at the context of the outliers, it was decided not to treat them.</u>\n",
    "\n",
    "- Maximum age is 98 and minimum age is 17 which is realistic and does not seem to be an error \n",
    "- The same is true for the campaign variable that the values seem realistic\n",
    "- pdays shows an outlier because the number 999 shows that a client was never contacted\n",
    "- The values in the previous column are also realistic and do not require adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Encode categorical variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 177 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Encode categorical variables as integer values\n",
    "# Categorical variables in any format will be converted to string\n",
    "# Note: All the NA values were imputed previously\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(pd.concat([train[cat_vars].astype(str), test[cat_vars].astype(str), validation[cat_vars].astype(str)], axis=0))\n",
    "# Apply on train, validation, test\n",
    "train[cat_vars] = enc.transform(train[cat_vars].astype(str))\n",
    "validation[cat_vars] = enc.transform(validation[cat_vars].astype(str))\n",
    "test[cat_vars] = enc.transform(test[cat_vars].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Finalize the processed data\n",
    "\n",
    "Current lists of variables:\n",
    "- id_var : customer ID\n",
    "- num_vars : numerical variables\n",
    "- cat_vars : categorical variables\n",
    "- na_vars : indicators for tracking missing values, bool [False, True]\n",
    "- target_var : target variable, subscribe [0, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 79.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Convert bool variable to int\n",
    "train[na_vars] = train[na_vars].astype(np.int8)\n",
    "validation[na_vars] = validation[na_vars].astype(np.int8)\n",
    "test[na_vars] = test[na_vars].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# id_var [ 1 ] : ['client_id']\n",
      "# num_vars [ 9 ] : ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate'] ...\n",
      "# cat_vars [ 10 ] : ['job', 'marital', 'education', 'default', 'housing'] ...\n",
      "# na_vars [ 9 ] : ['age_na', 'campaign_na', 'pdays_na', 'previous_na', 'emp.var.rate_na'] ...\n",
      "# target_var [ 1 ] : ['subscribe']\n",
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Print out the final variables\n",
    "print(\"# id_var [\", len(id_var), \"] :\", id_var)\n",
    "print(\"# num_vars [\", len(num_vars), \"] :\", num_vars[:5], \"...\")\n",
    "print(\"# cat_vars [\", len(cat_vars), \"] :\", cat_vars[:5], \"...\")\n",
    "print(\"# na_vars [\", len(na_vars), \"] :\", na_vars[:5], \"...\")\n",
    "print(\"# target_var [\", len(target_var), \"] :\", target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 30)\n",
      "(4000, 30)\n",
      "(10000, 29)\n",
      "Wall time: 8.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sort the data according to the variables list\n",
    "train = train[id_var + num_vars + cat_vars + na_vars + target_var]\n",
    "validation = validation[id_var + num_vars + cat_vars + na_vars + target_var]\n",
    "test = test[id_var + num_vars + cat_vars + na_vars]\n",
    "print(train.shape)\n",
    "print(validation.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Feature engineering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Quickly detect most (potentially) important varriables - Correlation test for numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 vars [+] correlated with target_var :\n",
      "previous         0.240116\n",
      "cons.conf.idx    0.052099\n",
      "age              0.034763\n",
      "Name: subscribe, dtype: float64\n",
      "\n",
      "Top 5 vars [-] correlated with target_var :\n",
      "cons.price.idx   -0.132582\n",
      "emp.var.rate     -0.299465\n",
      "euribor3m        -0.310996\n",
      "pdays            -0.335399\n",
      "nr.employed      -0.360334\n",
      "Name: subscribe, dtype: float64\n",
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Pearson's correlation for numerical variables\n",
    "corr = train[num_vars + target_var].corr(method='pearson')\n",
    "corr = corr[target_var[0]][:-1].dropna().sort_values(ascending=False)\n",
    "print(\"Top 5 vars [+] correlated with target_var :\"); print(corr[corr > 0][:5])\n",
    "print(\"\")\n",
    "print(\"Top 5 vars [-] correlated with target_var :\"); print(corr[corr < 0][-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Add polynomial terms for numerical variables\n",
    "\n",
    "<u>Note:</u> We only add the polynomial terms (degree=3) for a num variable if it increases the LR model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable age AUC vs. AUC poly: 0.49143272622017353 --> 0.6007377603416612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if enable_num_poly:\n",
    "    for v in num_vars:\n",
    "        # Setup the LR model\n",
    "        cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "        model = LogisticRegression(max_iter=200)\n",
    "        parameters = {}\n",
    "        clf = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=0)\n",
    "        \n",
    "        # Fit the LR model for 1 numerical variable\n",
    "        clf.fit(train[[v]], train[target_var].squeeze())\n",
    "        clf_num_score = clf.best_score_\n",
    "        \n",
    "        # Fit the LR model for 1 numerical variable + it polynomial degree = 3\n",
    "        poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "        poly.fit(train[[v]])\n",
    "        clf.fit(poly.transform(train[[v]]), train[target_var].squeeze())\n",
    "        clf_poly_score = clf.best_score_\n",
    "        \n",
    "        # Add the polynomial terms to train, validation test\n",
    "        if (clf_poly_score > 0.5) & (clf_poly_score - clf_num_score > 0.05):\n",
    "            print('Variable', v, 'AUC vs. AUC poly:', clf_num_score, '-->', clf_poly_score)\n",
    "            poly_vars = [v_poly.replace('x0', v) for v_poly in poly.get_feature_names()[1:]]\n",
    "            num_vars = num_vars + poly_vars\n",
    "            train[poly_vars] = pd.DataFrame(poly.transform(train[[v]])[:, 1:], columns=poly_vars)\n",
    "            validation[poly_vars] = pd.DataFrame(poly.transform(validation[[v]])[:, 1:], columns=poly_vars)            \n",
    "            test[poly_vars] = pd.DataFrame(poly.transform(test[[v]])[:, 1:], columns=poly_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Value transformation (num, cat => cat)\n",
    "\n",
    "- Categorical variable: remapping\n",
    "- Continuous variable: discretization\n",
    "\n",
    "\n",
    "<u>Reference:</u>\n",
    "\n",
    "- Coussement, K., Lessmann, S., & Verstraeten, G. (2017). A comparative analysis of data preparation algorithms for customer churn prediction: A case study in the telecommunication industry. Decision Support Systems, 95, 27-36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# List of variables to track the value transformation process\n",
    "trans_vars = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Remapping categorical variables - Decision tree–based remapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Apply the variable remmaping for all categorical variables\n",
    "\n",
    "<u>Note:</u> Only remap the variables if AUC > 0.5 and the number of new categories > 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remapping variable job from 13 to 11 categories\n",
      "Remapping variable marital from 5 to 3 categories\n",
      "Remapping variable education from 9 to 6 categories\n",
      "Remapping variable default from 4 to 3 categories\n",
      "Remapping variable housing from 4 to 2 categories\n",
      "Remapping variable contact from 3 to 3 categories\n",
      "Remapping variable month from 11 to 10 categories\n",
      "Remapping variable day_of_week from 6 to 2 categories\n",
      "Remapping variable poutcome from 4 to 3 categories\n",
      "Wall time: 2.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if enable_trans_cat_dt:\n",
    "    for v in cat_vars:\n",
    "        # Find the best decision tree using CV\n",
    "        cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "        model = DecisionTreeClassifier()\n",
    "        parameters = {'min_samples_leaf':(train.shape[0]*np.array([0.01, 0.025, 0.05, 0.1, 0.25, 0.5])).astype(int)}\n",
    "        clf = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=0)\n",
    "        clf.fit(train[[v]], train[target_var])\n",
    "        # Remap the variable on train, validation, test\n",
    "        if (clf.best_score_ > 0.5) & (clf.best_estimator_.get_n_leaves() > 1):\n",
    "            print(\"Remapping variable\", v,\n",
    "                  \"from\", train[[v]].nunique().values[0],\n",
    "                  \"to\", clf.best_estimator_.get_n_leaves(), \"categories\")\n",
    "            remap_var = v + '_remap'\n",
    "            trans_vars.append(remap_var)\n",
    "            train[remap_var] = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(train[[v]]).toarray()]\n",
    "            validation[remap_var] = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(validation[[v]]).toarray()]\n",
    "            test[remap_var] = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(test[[v]]).toarray()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Discretizing (or binning) numerical variables - Decision tree–based discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Apply the variable discretizing for all numerical variables\n",
    "\n",
    "<u>Note:</u> Only bin/discretize the variables if the number of new categories > 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretize variable age from [18.0, 95.0] to 39 categories\n",
      "Discretize variable campaign from [1.0, 56.0] to 7 categories\n",
      "Discretize variable pdays from [0.0, 999.0] to 3 categories\n",
      "Discretize variable previous from [0.0, 6.0] to 4 categories\n",
      "Discretize variable emp.var.rate from [-3.4, 1.4] to 8 categories\n",
      "Discretize variable cons.price.idx from [92.201, 94.767] to 14 categories\n",
      "Discretize variable cons.conf.idx from [-50.8, -26.9] to 15 categories\n",
      "Discretize variable euribor3m from [0.634, 5.045] to 47 categories\n",
      "Discretize variable nr.employed from [4963.6, 5228.1] to 9 categories\n",
      "Discretize variable age^2 from [324.0, 9025.0] to 39 categories\n",
      "Discretize variable age^3 from [5832.0, 857375.0] to 39 categories\n",
      "Wall time: 2.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if enable_trans_num_dt:\n",
    "    for v in num_vars:\n",
    "        # Find the best decision tree using CV\n",
    "        cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "        model = DecisionTreeClassifier()\n",
    "        parameters = {'min_samples_leaf':(train.shape[0]*np.array([0.01, 0.025, 0.05, 0.1, 0.25, 0.5])).astype(int)}\n",
    "        clf = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=0)\n",
    "        clf.fit(train[[v]], train[target_var])\n",
    "        # Remap the variable on train, validation, test\n",
    "        if (clf.best_score_ > 0.5) & (clf.best_estimator_.get_n_leaves() > 1):\n",
    "            print(\"Discretize variable\", v,\n",
    "                  \"from\", [train[[v]].min().values[0], train[[v]].max().values[0]],\n",
    "                  \"to\", clf.best_estimator_.get_n_leaves(), \"categories\")\n",
    "            remap_var = v + '_bin'\n",
    "            trans_vars.append(remap_var)\n",
    "            train[remap_var] = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(train[[v]]).toarray()]\n",
    "            validation[remap_var] = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(validation[[v]]).toarray()]\n",
    "            test[remap_var] = [np.nonzero(r)[0].max() for r in clf.best_estimator_.decision_path(test[[v]]).toarray()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3. Finalize value transformation\n",
    "\n",
    "- Finalize the variables list\n",
    "- Arrange the data columns\n",
    "\n",
    "<u>Note:</u> After the end of the value transformation step, we have these final lists of variables to manage:\n",
    "- num_vars\n",
    "- na_vars\n",
    "- cat_vars = cat_vars + trans_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed num, cat variables into # new categorical variables : 20\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Finalize the variable list\n",
    "cat_vars = cat_vars + trans_vars\n",
    "print(\"Transformed num, cat variables into # new categorical variables :\", len(trans_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 52)\n",
      "(4000, 52)\n",
      "(10000, 51)\n",
      "Wall time: 32.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Arrange the data columns\n",
    "train = train[id_var + num_vars + cat_vars + na_vars + target_var]\n",
    "validation = validation[id_var + num_vars + cat_vars + na_vars + target_var]\n",
    "test = test[id_var + num_vars + cat_vars + na_vars]\n",
    "print(train.shape)\n",
    "print(validation.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Value representation (cat => num)\n",
    "\n",
    "- Categorical variable: Dummy coding\n",
    "\n",
    "<u>Reference:</u>  \n",
    "\n",
    "- Coussement, K., Lessmann, S., & Verstraeten, G. (2017). A comparative analysis of data preparation algorithms for customer churn prediction: A case study in the telecommunication industry. Decision Support Systems, 95, 27-36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# List of variables to track the value representation process\n",
    "repr_vars = []\n",
    "dummy_vars = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1. Dummy coding\n",
    "\n",
    "<u>Note:</u> Here, we can fit the encoder on both train and test to make sure it captures all unique categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Apply the value representation for all categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 145 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if enable_repr_dummy:\n",
    "    # Create dummy variables, drop the first dummy column\n",
    "    enc = OneHotEncoder(drop=\"first\", handle_unknown=\"error\")\n",
    "    enc.fit(pd.concat([train[cat_vars], validation[cat_vars],  test[cat_vars]], axis=0))\n",
    "    dummy_vars = enc.get_feature_names_out().tolist()\n",
    "    repr_vars = repr_vars + dummy_vars\n",
    "    # Transform train, validation test\n",
    "    train_dummy = enc.transform(train[cat_vars])\n",
    "    validation_dummy = enc.transform(validation[cat_vars])    \n",
    "    test_dummy = enc.transform(test[cat_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2. Finalize value representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Drop categorical variables, add dummy variables\n",
    "\n",
    "At the end of this step, all categorical variables were represented by dummy variables or numerical variables. Therefore, it is no need to keep categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Drop cat vars\n",
    "if drop_cat_vars:\n",
    "    train = train.drop(cat_vars, axis=1)\n",
    "    validation = validation.drop(cat_vars, axis=1)\n",
    "    test = test.drop(cat_vars, axis=1)\n",
    "    cat_vars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add dummy variables\n",
    "if enable_repr_dummy:\n",
    "    train = pd.concat([train, pd.DataFrame(train_dummy.toarray(), columns=dummy_vars)], axis=1)\n",
    "    validation = pd.concat([validation, pd.DataFrame(validation_dummy.toarray(), columns=dummy_vars)], axis=1)\n",
    "    test = pd.concat([test, pd.DataFrame(test_dummy.toarray(), columns=dummy_vars)], axis=1)\n",
    "    del train_dummy, test_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Finalize the variables list\n",
    "\n",
    "<u>Note:</u> At the end of the value representation step, we have these final lists of variables to manage:\n",
    "- num_vars = num_vars + repr_vars\n",
    "- na_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Represented cat variables with # new num variables : 300\n",
      "Wall time: 997 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Combine the variable list\n",
    "num_vars = num_vars + repr_vars\n",
    "print(\"Represented cat variables with # new num variables :\", len(repr_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 322)\n",
      "(4000, 322)\n",
      "(10000, 321)\n",
      "Wall time: 93.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Arrange the data columns\n",
    "train = train[id_var + num_vars + cat_vars + na_vars + target_var]\n",
    "validation = validation[id_var + num_vars + cat_vars + na_vars + target_var]\n",
    "test = test[id_var + num_vars + cat_vars + na_vars]\n",
    "print(train.shape)\n",
    "print(validation.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Other data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  (a) Filter out low variance variables (or constant)\n",
    "\n",
    "During the data processing, we may accidentally create some new constant variables. Therefore, it is necessary to filter again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# List of all predictors\n",
    "predictors = num_vars + cat_vars + na_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop # constant vars : 0\n",
      "Wall time: 142 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Detect constant vars\n",
    "sel = VarianceThreshold(0)  # Var = 0 by default\n",
    "sel.fit(train[predictors])\n",
    "const_vars = [predictors[i] for i in np.where(sel.variances_ == 0)[0]]\n",
    "predictors = [v for v in predictors if v not in const_vars]\n",
    "\n",
    "# Drop from train, validation, test\n",
    "print('Drop # constant vars :', len(const_vars))\n",
    "train = train.drop(const_vars, axis=1)\n",
    "validation = validation.drop(const_vars, axis=1)\n",
    "test = test.drop(const_vars, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Drop duplicated variables\n",
    "\n",
    "Sometime, the data processing process can create a lot of duplicated variables. In this case, it is necessary to identify and drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# duplicated vars : 104\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Count the duplicated vars\n",
    "dup_vars = train[predictors].T.duplicated()\n",
    "print('# duplicated vars :', dup_vars.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Drop the duplicated vars from train, validation, test\n",
    "predictors = [predictors[i] for i in range(0, len(predictors)) if not dup_vars[i]]\n",
    "train = train[id_var + predictors + target_var]\n",
    "validation = validation[id_var + predictors + target_var]\n",
    "test = test[id_var + predictors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Export the processed data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 218)\n",
      "(4000, 218)\n",
      "(10000, 217)\n",
      "Wall time: 1.05 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Print out the data to check\n",
    "print(train.shape)\n",
    "print(validation.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save to pickle format\n",
    "train.to_pickle(\"C:/Users/hhussain1/Desktop/SML/Group Project/Pickles/train_processed.pkl\")\n",
    "validation.to_pickle(\"C:/Users/hhussain1/Desktop/SML/Group Project/Pickles/validation_processed.pkl\")\n",
    "test.to_pickle(\"C:/Users/hhussain1/Desktop/SML/Group Project/Pickles/test_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to CSV for submission\n",
    "\n",
    "train.to_csv(\"C:/Users/hhussain1/Desktop/SML/Group Project/train.csv\", index = False)\n",
    "validation.to_csv(\"C:/Users/hhussain1/Desktop/SML/Group Project/validation.csv\", index = False)\n",
    "test.to_csv(\"C:/Users/hhussain1/Desktop/SML/Group Project/test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Variable selection\n",
    "\n",
    "<u>Reference:</u>  \n",
    "\n",
    "- Verbeke, W., Dejaeger, K., Martens, D., Hur, J., & Baesens, B. (2012). New insights into churn prediction in the telecommunication sector: A profit driven data mining approach. European Journal of Operational Research, 218(1), 211-229."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read back the processed data\n",
    "train = pd.read_pickle(\"C:/Users/hhussain1/Desktop/SML/Group Project/Pickles/train_processed.pkl\")\n",
    "validation = pd.read_pickle(\"C:/Users/hhussain1/Desktop/SML/Group Project/Pickles/validation_processed.pkl\")\n",
    "test = pd.read_pickle(\"C:/Users/hhussain1/Desktop/SML/Group Project/Pickles/test_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create several lists to handle variables\n",
    "id_var = ['client_id']\n",
    "target_var = ['subscribe']\n",
    "predictors = [v for v in train.columns if v not in id_var + target_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Variable selection: Fisher Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def FisherScore(bt, target_var, predictors):\n",
    "    \"\"\"\n",
    "    This function calculate the Fisher score of a variable.\n",
    "\n",
    "    Ref:\n",
    "    ---\n",
    "    Verbeke, W., Dejaeger, K., Martens, D., Hur, J., & Baesens, B. (2012). New insights\n",
    "    into churn prediction in the telecommunication sector: A profit driven data mining\n",
    "    approach. European Journal of Operational Research, 218(1), 211-229.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the unique values of dependent variable\n",
    "    target_var_val = bt[target_var].unique()\n",
    "    # Calculate FisherScore for each predictor\n",
    "    predictor_FisherScore = []\n",
    "    for v in predictors:\n",
    "        fs = np.abs(np.mean(bt.loc[bt[target_var]==target_var_val[0], v]) - np.mean(bt.loc[bt[target_var]==target_var_val[1], v])) / \\\n",
    "             np.sqrt(np.var(bt.loc[bt[target_var]==target_var_val[0], v]) + np.var(bt.loc[bt[target_var]==target_var_val[1], v]))\n",
    "        predictor_FisherScore.append(fs)\n",
    "    return predictor_FisherScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 440 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>fisherscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nr.employed</td>\n",
       "      <td>0.747921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>euribor3m</td>\n",
       "      <td>0.706608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emp.var.rate</td>\n",
       "      <td>0.670617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.468189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>pdays_bin_4</td>\n",
       "      <td>0.467943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        predictor  fisherscore\n",
       "8     nr.employed     0.747921\n",
       "7       euribor3m     0.706608\n",
       "4    emp.var.rate     0.670617\n",
       "2           pdays     0.468189\n",
       "116   pdays_bin_4     0.467943"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate Fisher Score for all variable\n",
    "fs = FisherScore(train, target_var[0], predictors)\n",
    "fs_df = pd.DataFrame({\"predictor\":predictors, \"fisherscore\":fs})\n",
    "fs_df = fs_df.sort_values('fisherscore', ascending=False)\n",
    "fs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAERCAYAAAB2CKBkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0n0lEQVR4nO3deXxU9dX48c/JJJOVQDbWEIiyCLLKIiiCioi4L9W6omKlVH2qttpq1Vaftnax9ad9rCK11rpUqVoVlYqigoIbYVVAFNkSQMjCmn05vz/uJQ4hCQPkzkwy5/163dfMnXvnzuFq5sx3F1XFGGNM9IoJdwDGGGPCyxKBMcZEOUsExhgT5SwRGGNMlLNEYIwxUc4SgTHGRLnYcAdwqDIzM7Vnz57hDiM4a9Y4j337hjcOY0zUW7x4cZGqZjV2rNUlgp49e5KXlxfuMIJz8snO47x54YzCGGMQkY1NHWt1iaBVufvucEdgjDEHZYnAS6edFu4IjDHmoKyx2EvLljmbMcZEMCsReOmWW5xHayMwUaS6upqCggIqKirCHUpUSkhIIDs7m7i4uKDfY4nAGNOiCgoKaNeuHT179kREwh1OVFFViouLKSgoIDc3N+j3WdWQMaZFVVRUkJGRYUkgDESEjIyMQy6NRU0iqK1TCnaUUVNbF+5QjGnzLAmEz+Hc+6hJBLOWb2bMH95nQ3FZuEMxxnjM5/MxZMiQ+m3Dhg2ccMIJzb4nJSWlxT6/rq6OH//4xwwYMICBAwcyYsQI1q9f32LXb2lR00bQPS0JgPwdZfTq2HL/wZt1//2h+RxjzH4SExNZ1qDH3kcffeTZ59XU1BAb+93X6cyZM9myZQsrVqwgJiaGgoICkpOTW/QzWlLUlAi6pzuJoKAkhCWCE05wNmNM2O37xb9161bGjh3LkCFDGDBgAB9++GH9OXfddReDBw9m1KhRbNu2DYDCwkIuuugiRowYwYgRI1i4cCEA9957L1OnTuX0009n8uTJ+33W1q1b6dKlCzExzldsdnY2aWlpALz11lscd9xxDB48mPHjxwNQUlLC+eefz6BBgxg1ahQrVqxo9DOaiuVIRU2JICslHn9sDPk7ykP3oft+gVgyMFHqvtdXsmrL7ha9Zv+uqfzqnGObPae8vJwhQ4YAkJubyyuvvFJ/7F//+hcTJ07krrvuora2lrIy58dhaWkpo0aN4re//S0/+9nP+Nvf/sbdd9/NzTffzK233sqYMWPYtGkTEydOZPXq1QAsXryYBQsWkJiYuN/nX3LJJYwZM4YPP/yQ8ePHc+WVVzJ06FAKCwu5/vrr+eCDD8jNzaWkpASAX/3qVwwdOpRXX32V9957j8mTJ9eXaAI/4/LLL28yliMRNYkgJkbITktkUyjbCH7xC+fRxhEYE1KNVQ3tM2LECKZMmUJ1dTXnn39+fcLw+/2cffbZAAwbNox33nkHgLlz57Jq1ar69+/evZs9e/YAcO655x6QBMApAaxZs4b33nuP9957j/Hjx/Piiy9SVlbG2LFj67t2pqenA7BgwQJefvllAE499VSKi4vZtWvXAZ/RVCzt2rU7rPu0T9QkAnDaCfJ3WGOxMaFysF/u4TB27Fg++OAD3nzzTa666ipuv/12Jk+eTFxcXH2PG5/PR01NDeA0/H788ceNfuE3V+8fHx/PpEmTmDRpEp06deLVV19lwoQJjfbqUdUDXtt3XuBnNBfLkYiaNgKAnPQk8kPZRmCMiTgbN26kY8eOXH/99Vx33XUsWbKk2fNPP/10Hnnkkfr9pkoagZYsWcKWLVsA58t7xYoV9OjRg9GjRzN//vz6HkT7qobGjh3Lc889B8C8efPIzMwkNTW1RWIJRnSVCNIT2V1Rw67yatonBj/82hjTdsybN48HHniAuLg4UlJSePrpp5s9/y9/+Qs33ngjgwYNoqamhrFjxzJ9+vRm37N9+3auv/56KisrARg5ciQ33XQTCQkJzJgxgwsvvJC6ujo6duzIO++8w7333su1117LoEGDSEpK4p///GeLxRIMaaxIEsmGDx+uh7sewX8/38qPnlvCG/8zhgHd2rdwZI2w9QhMFFq9ejX9+vULdxhRrbH/BiKyWFWHN3Z+lJUI3LEEJWWhSQQPPeT9ZxhjzBHytI1ARM4QkTUislZE7mjk+O0isszdvhCRWhFJ9yqewEFlITFkiLMZY0wE8ywRiIgP+CswCegPXCYi/QPPUdUHVHWIqg4B7gTmq2qJVzG1T4ojNSGWTaFqMJ4719mMMSaCeVk1NBJYq6rrAETkBeA8YFUT518GPO9hPADkZiazoShEieA3v3EebaUyY0wE87JqqBuQH7Bf4L52ABFJAs4AXm7i+FQRyRORvMLCwiMKKjczmfVFpUd0DWOMaUu8TASNzYXaVBelc4CFTVULqeoMVR2uqsOzsrKOKKjczBQ27yynorr2iK5jjDFthZeJoADoHrCfDWxp4txLCUG1EEBuljNKb0OxlQqMaYuKi4vrp5/u3Lkz3bp1q9+vqqoK6hoPPvgg/fv3Z9CgQYwfP56NGzfWH/vnP/9J79696d27d5P9/VsbL9sIFgG9RSQX2IzzZX95w5NEpD0wDrjSw1jqHZXpJIL1haUc0/nAkXvGmNYtIyOjfsTtvffeS0pKCrfddtshXWPo0KHk5eWRlJTEY489xs9+9jNmzpxJSUkJ9913H3l5eYgIw4YN49xzz62fWbS18qxEoKo1wE3AHGA18G9VXSki00RkWsCpFwBvq2pIfqL3dBPBulC0Ezz+uLMZY8Lq3XffZejQoQwcOJApU6bUj/jt2bMnP//5zxk5ciQjR45k7dq1AJxyyikkJTndzUeNGkVBQQEAc+bMYcKECaSnp5OWlsaECRN46623wvOPakGeDihT1dnA7AavTW+w/xTwlJdxBEqJj6Vju/jQNBj37ev9ZxgT6faNsA90ySVwww1QVgZnnnng8WuucbaiIvje9/Y/dogj9SsqKrjmmmt499136dOnD5MnT+axxx7jlltuASA1NZXPPvuMp59+mltuuYU33nhjv/f//e9/Z9KkSQBs3ryZ7t2/q/HOzs5m8+bNhxRPJIqqSef2OSorRD2HXn/d2YwxYVNbW0tubi59+vQB4Oqrr+aDDz6oP37ZZZfVP3788cf7vffZZ58lLy+P22+/HWh+ltDWLKqmmNgnNzOFt77Y6v0H/fnPzuM553j/WcZEquZ+wSclNX88M/OI5+o62BKRgV/kgc/nzp3Lb3/7W+bPn098fDzglADmBcRTUFDAyY2VeFqZqCwRdEqNZ0dZNbV1rWvCPWPMoauoqGDDhg319f/PPPMM48aNqz8+c+bM+sfRo0cDsHTpUn74wx8ya9YsOnbsWH/uxIkTefvtt9mxYwc7duzg7bffZuLEiSH813gjKksE/lgn/1XV1JHo94U5GmOMlxISEvjHP/7BxRdfTE1NDSNGjGDatO/6q1RWVnL88cdTV1fH8887vdhvv/129u7dy8UXXwxATk4Os2bNIj09nXvuuYcRI0YA8Mtf/rJ+lbHWLDoTgc9NBLV1JGKJwJi26t57761/vnTp0kbPufHGG/nVr36132tzm5kjbMqUKUyZMqVF4osUUVk1FB9QIjDGmGgXnSWC2O9KBJ565hlvr2+MOSIbNmwIdwgRISoTQZwvRCWC7t0Pfo4xxoRZVFYN7SsRVHtdIpg509mMiTKtbQnctuRw7n10JoJQlQgee8zZjIkiCQkJFBcXWzIIA1WluLiYhISEQ3pfVFYN7SsRVFpjsTEtLjs7m4KCAo507RBzeBISEsjOzj6k90RnIghVicCYKBQXF0dubm64wzCHIDqrhkLVRmCMMa1AVCcCKxEYY0y0Vg2FahzBSy95e31jjGkBUZkIQjaOIDPT2+sbY0wLiM6qIV+ISgRPPeVsxhgTwTxNBCJyhoisEZG1InJHE+ecLCLLRGSliMz3Mp59QjbXkCUCY0wr4FnVkIj4gL8CE4ACYJGIzFLVVQHndAAeBc5Q1U0i0rHRi7Uwayw2xpjveFkiGAmsVdV1qloFvACc1+Ccy4H/qOomAFXd7mE89ULWWGyMMa2Al4mgG5AfsF/gvhaoD5AmIvNEZLGITPYwnnr7GourrURgjDGe9hpqbEXnhpOPxALDgPFAIvCxiHyiql/tdyGRqcBUcFYKOlKxMYKIlQiMMQa8TQQFQOA8zNnAlkbOKVLVUqBURD4ABgP7JQJVnQHMABg+fPgRz2QlIvh9Md63Ecye7e31jTGmBXhZNbQI6C0iuSLiBy4FZjU45zXgJBGJFZEk4HhgtYcx1fPHxng/6VxSkrMZY0wE86xEoKo1InITMAfwAU+q6koRmeYen66qq0XkLWAFUAc8oapfeBVTIL8vxvuqoUcfdR5vuMHbzzHGmCPg6chiVZ0NzG7w2vQG+w8AD3gZR2P8sTHeNxb/+9/OoyUCY0wEi8qRxeAkAmssNsaYaE4EoWgsNsaYViBqE0GcJQJjjAGiOBFY1ZAxxjiichpqcBOB1yWCefO8vb4xxrSAqC0RxFuJwBhjgChOBCFpLP7Tn5zNGGMiWNQmgjhfjPeL17/xhrMZY0wEi9pEEJI2AmOMaQUsERhjTJSL7kRgjcXGGBPF3UdD0VicmOjt9Y0xpgVEbyIIRYngv//19vrGGNMCordqyKaYMMYYIJoTQWwMdQo1XpYKfv1rZzPGmAgWtYmgfgH72iNe+bJp777rbMYYE8GiNhH4Y51/ulUPGWOiXdQngsra2jBHYowx4eVpIhCRM0RkjYisFZE7Gjl+sojsEpFl7vZLL+MJFO+zEoExxoCH3UdFxAf8FZgAFACLRGSWqq5qcOqHqnq2V3E0ZV+JwNM2gowM765tjDEtxMtxBCOBtaq6DkBEXgDOAxomgrCIC0WJ4OWXvbu2Mca0EC+rhroB+QH7Be5rDY0WkeUi8l8RObaxC4nIVBHJE5G8wsLCFgnOGouNMcbhZSKQRl5rWA+zBOihqoOB/wNebexCqjpDVYer6vCsrKwWCa4+EXjZWHznnc5mjDERzMuqoQKge8B+NrAl8ARV3R3wfLaIPCoimapa5GFcgDOyGKCqxsM2go8/9u7axhjTQrwsESwCeotIroj4gUuBWYEniEhnERH3+Ug3nmIPY6rnj3UKLDYDqTEm2gVdIhCRZFUtDfZ8Va0RkZuAOYAPeFJVV4rINPf4dOB7wI9EpAYoBy5VVQ9/on/H7/MB1kZgjDEHTQQicgLwBJAC5IjIYOCHqnrDwd6rqrOB2Q1emx7w/BHgkUMNuiVYY7ExxjiCqRr6f8BE3CobVV0OjPUyqFAISWNxdrazGWNMBAuqakhV892q/H1a/bwMcT7n31O8t4rq2rr6cQUt6tlnW/6axhjTwoL59st3q4dURPwichuw2uO4PJcS7+TA37y5mounW+8eY0z0CiYRTANuxBkMVgAMcfdbtQ5Jfp77wfFcNjKHZfk7Wb1198HfdKhuucXZjDEmgjVbNeTOF/SQql4RonhC6sRemfTrksqLefm8snQz/bqktuwHLFvWstczxhgPNFsiUNVaIMsdB9AmpSf7OblvR15btpnaupD0XDXGmIgSTGPxBmChiMwC6scRqOqDXgUVaucP7crc1dtYlr+TYT3Swh2OMcaEVDCJYIu7xQDtvA0nPHp1TAHg210VYY7EGGNC76CJQFXvAxCRds6u7vU8qhDLTIkHoGhvZcteuE+flr2eMcZ4IJiRxQOAZ4B0d78ImKyqKz2OLWTSkvzECBS3dCKYMaNlr2eMMR4IpvvoDOAnqtpDVXsAPwX+5m1YoeWLEdKT/RTurQp3KMYYE3LBJIJkVX1/346qzgOSPYsoTDJT4lu+amjqVGczxpgIFkxj8ToRuQenegjgSmC9dyGFR0aKv+UTwVdftez1jDHGA8GUCKYAWcB/3C0TuNbLoMIhMyWeYqsaMsZEoWB6De0AfhyCWMLKk6ohY4xpBQ5aIhCRd0SkQ8B+mojM8TSqMMhI8VNWVUtZVU24QzHGmJAKpo0gU1V37ttR1R0i0tG7kMKjfizBnipyMlpoKechQ1rmOsYY46Fg2gjqRCRn346I9ACCmpRHRM4QkTUislZE7mjmvBEiUisi3wvmul7IchNBYUtWDz30kLMZY0wEC+an713AAhGZ7+6PBQ7aJ9KdufSvwASc6asXicgsVV3VyHl/wFnbOGz2lQhafFCZMcZEuGAai98SkeOAUe5Lt6pqURDXHgmsVdV1ACLyAnAesKrBef8DvAyMCDpqD2SkOBOsFrVkz6Err3QebaUyY0wEa7JqSER6iEh7APeLvxTn1/3kIKel7gbkB+wXuK8FfkY34AJgOmH2XSJowRJBQYGzGWNMBGuujeDfuCOIRWQI8CKwCRgMPBrEtaWR1xq2LTwE/Nxd96DpC4lMFZE8EckrLCwM4qMPXXysj9SEWOtCaoyJOs1VDSWq6hb3+ZXAk6r6ZxGJAZYFce0CoHvAfjbOdNaBhgMviAg4A9XOFJEaVX018CRVnYEz5xHDhw/3bPWYzu0TWF9UevATjTGmDWmuRBD4i/5U4F0AVa0L8tqLgN4ikutWJV0KzAo8QVVzVbWnqvYEXgJuaJgEQunUYzrx0TfFViowxkSV5hLBeyLybxF5GEgD3gMQkS7AQVtUVbUGuAmnN9Bq4N+qulJEponItCMPveVdeFw3auuU15c3LLgcptGjnc0YYyKYqDZe0yJOfc33gS44X+Kb3deHAh1VNSzdPYcPH655eXmeXf+sv3xIbIzw2k1jPPsMY4wJNRFZrKrDGzvWZIlAHS+o6v/blwTc15eGKwmEwgVDu7G8YBertuwOdyjGGBMSwYwsjioXD+tOkt/H3xe0wEzbF13kbMYYE8EsETTQPimOS4Z3Z9byzWwsLqWpqrOgFBc7mzHGRLBmE4GI+EQk6obFXntiT2rrlHEPzOPcRxYeWTIwxpgI12wicAd6ZQU5krjN6JGRzH9uOJHLj8/h8827WJa/M9whGWOMZ4KZdG4DsFBEZuFMMwGAqj7oVVCRYEj3DhyVlcxLiwuYtXwLQ3PSwh2SMcZ4Ipg2gi3AG+657QK2Ni81IY5T+mbxxoqt1NYdRvXQ+PHOZowxESyY2UfvAxCRZFWNuvkXzhvSjTkrt/HB14Wc0vcQ1+O55x5vgjLGmBYUzFKVo0VkFc7oYERksIgEM+lcmzC+X0e6tk/goblfW6OxMaZNCqZq6CFgIlAMoKrLcRaniQrxsT5uPq03y/N38vaqbYf25kmTnM0YYyJYUOMIVDW/wUvNThvd1lx0XDZHZSVz68xl/OXdr3l75bcs2lDC1l3lzb+xvNzZjDEmggXTayhfRE4A1O1G+mPcaqJoEeuL4ekpI7l31koefOer/Y4Nzm7Pj07uxcRjO+FOp22MMa1KMIlgGvAwzupiBcDbwI1eBhWJstOSeOLqEWzdVU7Rnip2lFWxautuXszLZ9qzi7lsZA6/u3BguMM0xphDFkyvoSLgihDE0ip0aZ9Il/aJAIztk8UPxuRy+0sreHlxAb88uz+Jfl+YIzTGmENz0EQgIlnA9UDPwPNVdYp3YbUesb4YzhvSlVeWbuazDSWM65P13cGzzw5fYMYYE6RgqoZeAz4E5hJljcTBGpmbjt8Xw8K1RfsngttuC19QxhgTpGASQZKq/tzzSFqxJH8sx/XowIKvi8IdijHGHLJguo++ISJneh5JKzemVyartu7ef73jk092NmOMiWBNJgIR2SMiu4GbcZJBuYjsDnj9oETkDBFZIyJrReSORo6fJyIrRGSZiOSJSKtdH3L00ZkALFpfEuZIjDHm0DS3VGU7VU11H2NUNTFgP/VgFxYRH/BXYBLQH7hMRPo3OO1dYLCqDgGmAE8c9r8kzAZ0S8Xvi2GpTVltjGllgplr6EQRSXafXykiD4pIThDXHgmsVdV1qloFvACcF3iCqu7V7ybwSQZa7WQ+8bE+ju2WypKNO8IdijHGHJJg2ggeA8pEZDDwM2Aj8EwQ7+sGBE5NUeC+th8RuUBEvgTexCkVHEBEprpVR3mFhYVBfHR4HJeTxuebd1FVUxfuUIwxJmjBJIIa91f7ecDDqvowwa1H0Nh8Cwf84lfVV1T1GOB84NeNXUhVZ6jqcFUdnpWV1dgpEWFoTgcqa+pYvdVtQrnkEmczxpgIFkz30T0icidwJTDWrfuPC+J9BUD3gP1snEVuGqWqH4jI0SKS6Y5mbnWOc1cxW7ppB4O7d4AbbghvQMYYE4RgSgTfByqB61T1W5zqnQeCeN8ioLeI5LqT1V0KzAo8QUR6iTtTm4gcB/hxp7tujbp2SKRL+wQWrHX/CWVlzmaMMREsmLmGvgUeDNjfBDwdxPtqROQmYA7gA55U1ZUiMs09Ph24CJgsItVAOfD9gMbjVun8od14fP435JeU0f1Cd/jFvHlhjckYY5rTZCIQkQWqOkZE9rB/3b4AGkwXUlWdDcxu8Nr0gOd/AP5wyFFHsMmjezDjg3X886MN3B3uYIwxJgjNVQ1dAfuNJ9i3BTWOIFp1aZ/ImQO7MHNR/uEteG+MMSHWXCJ4Zd8TEXk5BLG0GVNO7MmeyhoK91Qe/GRjjAmz5hJBYPfPo7wOpC0ZmpPG0JwObN1d0XpHyBljokZzjcXaxHMThCkn5vLcm6ewa1AXTqpTfDG2jKUxJjI1lwgGu5PLCZAYMNFc0I3F0eyMAZ155txLuGZ9Cd3++D4jeqbRuX0ix3Rux/h+HWmXEMxQDGOM8V6TiUBVbc3FIxDni2Hmhb2Yu3obL22s4JN1JRSXVlJd6xSu4mNjGH10Bjec3IuRuelhjtYYE82CGVlsDpNcfDETgAnuOIK6OmVp/g4+WltMcWkVb6zYwiWPf8wPxuTyP6f2pn2SlRKMMaFniSCEYmKEYT3SGdbDKQHcMekY7p+9micWrOfJhes5e1BXHrh4EPGxVhgzxoSOJYIwSojz8b/nDeDC47J5Y/kWnliwnrKqGh65/DgS4iwZGGNCwxJBBBjSvQNDunegR0YS97y2ksv/9gl3ndWfnPQkstrFhzs8Y0wbZ4kgglw1uieZKfH85N/LueixjwDo26kd143J5XvDsomxLqjGGA9YIvDSj350yG+ZNLALg7t3YNWW3XxTuJfZn2/lZy+vYGZePr85fwD9ulivXWNMy5LWNtnn8OHDNS8vL9xhhExdnfLykgJ+998v2VVezfPXj7LupsaYQyYii1V1eGPHglmPwByu/HxnOwIxMcLFw7vz7k/GkZHs5+F3v2qh4IwxxmGJwEtXXeVsLSAt2c/1Jx3FwrXFLN20o0WuaYwxYImgVbn8+BzaJ8bxv2+sorSyJtzhGGPaCEsErUhyfCy/u3AgKwp2ccUTn/KvTzexo7Qq3GEZY1o5TxOBiJwhImtEZK2I3NHI8StEZIW7fSQig72Mpy04c2AX/nLpUDYWl/KLVz7njIc/IG9DSbjDMsa0Yp4lAhHxAX8FJgH9gctEpH+D09YD41R1EPBrYIZX8bQlZw3qwpJ7JvDqjSeSEOfjsr99wpsrtoY7LGNMK+XlOIKRwFpVXQcgIi8A5wGr9p2gqh8FnP8JkO1hPKH30596dmkRYUj3Dsy6cQzX/XMRNz2/hPtnJ3J0xxQm9O/EpSO6E+ezmj9jzMF5mQi6AYF9JwuA45s5/zrgvx7GE3rnnOP5R7RPiuOZ647n8Q++YWNxGcsLdnLPq18wd9U2Hr3iOJLjbcygMaZ5Xn5LNDYfQqOj10TkFJxEMKaJ41OBqQA5OTktFZ/31qxxHvv29fRjEv0+bjmtT/3+859t4q5XPmfcA/O4enQPLhyWTbcOiZ7GYIxpvTwbWSwio4F7VXWiu38ngKr+rsF5g4BXgEmqetDRUq1qZPHJJzuP7noEoZS3oYT/e28t878qBGBAt1TG9MripN6ZDOuRZrObGhNlmhtZ7GWJYBHQW0Rygc3ApcDlDQLLAf4DXBVMEjDBG94znX9OGcmm4jJmLd/MB18V8cSH65g+/xsS4mI4f0g37jqrny2ZaYzxLhGoao2I3ATMAXzAk6q6UkSmucenA78EMoBHRQSgpqmMZQ5PTkYSN53am5tO7c3eyho+XVfM3NXbmbloE+9+uZ0RPdMY0yuLswZ2sRXSjIlSNumcl8JYNXQwizfuYMYH3/DF5t1s3lmO3xfDuL5ZHNs1laOyUhjWI42u7RNwE7QxppULV9WQiWDDeqTx+FXDUVW+2LybV5ZuZs7Kb3ln1bb6czqnJtC/ayqDstszZUwuqVaNZEybZCUCL82d6zyedlp44zgElTW1fL1tL4s37mDxxh18tW0Pa7btITMlnnF9suielkTXDgkkx8cyMjedzBRbQc2Y1qC5EoElAnNQKwp28qe3v+Krb/ewbU8F+/6XyUlP4s0fj7EGZ2NaAUsE4bJsmfM4ZEg4o2hRlTW1bNtVyepvd/OjZxdzxoDO/GhcL47tmmpLaRoTwayNIFxuucV5jMDG4sMVH+sjJyOJnIwkbj2tD39+5ytmf/4tJ/XO5PGrhpHkt/+ljGltbDIac9j+Z3xv5v5kLHef1Y+Fa4u46LGPeWVpARXVteEOzRhzCOznmzkivTq2o1fHdvTISOb+2au5deZy7nt9FeP6ZNEzI5kzB3ahb+d24Q7TGNMMSwSmRUzo34nT+nXk42+K+ddnm1i8cQdvrNjKw+9+TbcOiQzrkcbVJ/RkWI+0cIdqjGnAEoFpMSLCCb0yOaFXJgAlpVW8vnwLizfuYP5XhcxavoV+XVI549jODMxOZUDX9nRMTQhz1MYY6zXkpY/c5RZOOCG8cUSA0soa/rOkgJeWbGZ5/s7619OT/QzrkcafLxlsA9aM8ZB1HzURZU9FNau37mHlll18uXUPLy0p4IwBnXnksqE2pYUxHrHuo+FiJYJGtUuIY2RuOiNz0wFnYrwH5qwhI9nPTyb0oUOSP8wRGhNdLBF46Re/cB7b0DgCL/xo3NFs3VXOM59s5NWlm7np1F5MHt3T1kwwJkRsHIEJu5gY4TfnD+S/N5/EcT3SuH/2l4z/83xeW7aZurrWVXVpTGtkJQITMY7pnMpT145k4doi7p+9mptfWMYj760lJz2JBL+P9CQ//bumMvHYzqQnW/WRMS3FGou9FMHrEUS6ujrlteWbeeGzfPZW1lBeXUvhnkr2VNSQGOfjzIFdGJLTgXMGdbE2BWOCYI3FptWJiREuGJrNBUOz619TVb78dg9PfLie99ds5+UlBfx+9mpG5qbTt3Mqt53eh1if1XYac6g8TQQicgbwMM5SlU+o6u8bHD8G+AdwHHCXqv7Jy3hC7qGHwh1BmyIi9OuSyp8vGYyqsnrrHv6+YD0rt+zi/TWFZKclcuWoHuEO05hWx7OqIRHxAV8BE4ACnMXsL1PVVQHndAR6AOcDO4JJBK2qasiEhKpyyeMfs76olPdvO9nWRzCmEeGqGhoJrFXVdW4QLwDnAfWJQFW3A9tF5CwP4wifVrhCWWskIvzizH5c8OhHDLrvbTq2i+eYzqn065JKN3c1tWO7tqd7eiKJcT4btGZMA14mgm5AfsB+AXC8h58XeX7zG+fREoHnhuak8dS1I1i6aSf5JWWs2rqbhWuLqGnQ/bRbh0QeuXwoQ3Ns8jtj9vEyETT2s+uw6qFEZCowFSAnJ+dIYjJt2Ml9O3Jy3471+1U1dewqr2ZXeRWfb97Ft7sqef6zTXz/8U/IzUymQ1Icx3Ztz9SxR9G5vU1+Z6KXl4mgAOgesJ8NbDmcC6nqDGAGOG0ERx6aiQb+2Biy2sWT1S6eXh2dNREuHdGd/zf3K7bvrmTbngqe/XQjLy8p4IfjjmJcnyyOzkqxEc0m6niZCBYBvUUkF9gMXApc7uHnGXNQacl+/ve8AfX76wr3cud/PuePb63hj2+tIUbggqHZ3H1WP9Js0JqJEp4lAlWtEZGbgDk43UefVNWVIjLNPT5dRDoDeUAqUCcitwD9VXW3V3EZE+iorBRm/nA0W3eV89n6EpZu2smzn2zkzc+3cFLvLG47va+tsGbaPBtZ7KU1a5zHvn3DG4c5JF9+u5vnP93E6yu2UlpZw/UnHcUpx2QxrEd6uEMz5rDZegTGHIbteyq44+XPeX/NdlTh3nP6c82JueEOy5jDYlNMhMvrrzuP55wT3jjMYenYLoEnrxnBrvJqbn9xOfe+vopP15fQKTWBrHbxDO+RxuDuHYjzxeCLsbEJpvWyEoGXbNK5NqOiupZfvPI5SzftpGhPJXsqa+qPiUCndgkM6JbK2D5ZnNQ7i54ZSTZwzUQUKxEYc4QS4nw8eMmQ+v3dFdUs+LqI9UWlVFbXUrCznLwNO5i7ejsAyX4f/bqkcvqxnZh4bGd6ZCSHKXJjDs4SgTGHITUhjjMHdjng9Y3FpSxYW8TX2/aSt7GE+2d/yf2zv6RDUhxJcT6S4mPpkZ7EgG7tGZTdniHdO5CREh+Gf4Ex37FEYEwL6pGRvN+v//ySMt5etY2NxaWUVdWyt6KGbwr38p7bAA0wOLs9Pxx3ND0zkkmO99EhyU/7RJs4z4SOJQJjPNQ9PYnrxhzY06i0soaVW3aTt7GEFz7L54bnljR4XyJZKfF0Sk1gZG46PTOS6du5HV07JIYqdBNFrLHYS/nunHvduzd/nolq1bV1LFpfwu6Kakora9m+p5IvNu9iV3k164tK2byzvP7c7LREOiTFkRjnIyM5nuE90zh3SFc6trO5kkzzbByBMa3Ytt0VFOwoY+mmnSzL30l5VS3l1bUU7ChnU0kZfl8MEwd0ZvRRGaQmxpKe7Kd7WhKd2ycQZyu2GZf1GgqXmTOdx+9/P7xxmFatU2oCnVITGh3ZvK5wL39fsJ45K7/l9eX7z+kYI9ClfSLdOiSSnZZIj4xkemYmkZ2WRGaKn0S/D78vhvhYHwlxMdbdNYpZicBLNo7AhEhdnbJ5Zznl1bUU7amkYEc5BTvK3Mdy8neUsXVXRZPvF4Gu7RMZ0TONS0Z0Z1RuBjE2SK5NsRKBMW1cTIzQPT0JgD6dGp8kr6K6lvwSJzkUl1ZRXl1LVU0dVTV1lFXVsK6olPlfFfLqsi3ECKQl+UlL9tMzI5nstESS/D4GdmtP707tyEh2ejZZsmgbLBEYEyUS4nz07tSO3k0kCnCSxVtffMs3hXspKa2iaG8la7fv5dN1xZRX1+634luMQIckP5kpfrp2cKqg0pL8JMX7GHVUBrkZycTFxuD3xeCPtbaKSGaJwBhTLyHOx/lDuzV6rKqmji+27CK/pIyS0ip2lFZRUlbF9t2VbN5ZzrL8newur6aukdrmfl1SGd4jjcyUeDJS/PXdYdslxBIfa+0T4WaJwBgTFH9sDMflpHHcQdZ73llWxcK1xRTuqaCqto69lbV8sq6Y15ZtZndFzQHni0C8W3LomZlM1/aJJMfHkhzvI8kfS0q8z92PJTHOR5xPiI2JwecT4mKc0sag7Pa2stwRsETgpZdeCncExoRchyQ/Zw06cPoNcEoVJaVVrN2+l28K91JWVUt5VQ0VNXWUV9WyvqiUdUV7Ka2spbSqhrLKWqpq6w76mT0ykrhz0jEM75lOepLf2i4OkfUaMsZEtKqaOkora9hbWUNlTS3VtUpNrVJdV0dNrVK4p5I/zvmSjcVl9e9JcUsU8bE+Tu/fiZ+e3pdEf3SXGKzXULg89ZTzeM014YzCmFbNHxuDP9bf7BrS4/t1ZMmmHXy5dQ87y6vZW1FDaWUNxaVVPLFgPbOWb+GUvh3JahdPUryPrJR4OqYm0CExjvaJcWSnJRIbxYPvPE0EInIG8DDOmsVPqOrvGxwX9/iZQBlwjaouOeBCrZUlAmNCIiHOxwlHZ3LC0ZkHHPtkXTFPLljPf7/YSmlVLbWNtGb7Y2NITYjF74shwe8jJz2JTu0SiI+LISHOR9f2CRzdMYWMZKexOy3J36Z6QnmWCETEB/wVmAAUAItEZJaqrgo4bRLQ292OBx5zH40xpkWMOiqDUUdl1O+XVdVQuKeS7Xsq2VNRTdHeKr7Zvpc9lTX1Yyo2FJWxeutuKt22i8qaA9sp2iXEkpHsJzczmX5dUkmOjyUhzhmlnRDrIyHOR6LfeR7vvp4Y53PP+e68SGjP8LJEMBJYq6rrAETkBeA8IDARnAc8rU5DxSci0kFEuqjqVg/jMsZEsSR/LD0yYoNeLEhV2b6nkg1FpZSUVlFcWkWJuxXtrWTNt3uY/1Vho91mg+GPjSEhNsZNHD43icQQH+cjMc5H59QEenVMIdYnDOzWnuE9D5xq5Eh5mQi6AfkB+wUc+Gu/sXO6AfslAhGZCkwFyMnJafFAjTGmKSJSP99TU1SVqto6KqrrqKiudTfneXnAfmVNLeVV7n7Nd8crA95XHvDenWVVfL55FzPznK/JaeOObnWJoLHyTsOcGcw5qOoMYAY4vYaOPDRjjGk5IkJ8rNNLqaUXFVJVdlfUoKrEx3rT88nLRFAABE7Enw1sOYxzWq/Zs8MdgTGmlRMRz1es87LZexHQW0RyRcQPXArManDOLGCyOEYBu9pU+0BSkrMZY0wE86xEoKo1InITMAen++iTqrpSRKa5x6cDs3G6jq7F6T56rVfxhMWjjzqPN9wQ3jiMMaYZNrLYS7YegTEmQjQ3srjtjIgwxhhzWCwRGGNMlLNEYIwxUc4SgTHGRLlW11gsIoXAxsN8eyZQ1ILhtCV2b5pm96Zpdm+aFmn3poeqZjV2oNUlgiMhInlNtZpHO7s3TbN70zS7N01rTffGqoaMMSbKWSIwxpgoF22JYEa4A4hgdm+aZvemaXZvmtZq7k1UtREYY4w5ULSVCIwxxjRgicAYY6KcJQJjjIlybT4RiEhfERktInEi4s3yPq2ciHQXEb+IJLv7bf7/C2PMd9p0Y7GIXAjcD2x2tzzgKVXdHdbAIoiInAX8AVgIpAH3qOoaEYlR1brwRhcZ3IWVUNWqcMcSaezeNE1EJgB9gBhV/T8REY3QL9w2+8tPROKA7wPXqep44DWcZTF/JiKpYQ0uArirwnUHfg/cBPwS+BR4X0SOVdU6KxmAiFwE/At4Q0TOEpG0cMcUKezeNE1ExuDcmwrg+yLyf8CJIuLl8sCHra3/oacCvd3nrwBvAH7gchGRsEUVAdSRD3wMfAVsV9U/4ySGt0WkT7SXCESkD/Ab4M/AP4Af4iytenRYA4sAdm8OaiTwiKr+HTgN2AV8DxgR1qia0GYTgapWAw8CF4rISe6X2gJgGTAmnLGFm4icIyK3uqWmVOCafUVWVf0L8DDwCxFJiPKEmQZsU9WPVfV54HfAAOBMEWkX3tDCLh27N835HBjt/qCqAH6NsxzvFeENq3FtNhG4PgTeBq4SkbGqWquq/wK6AoPDG1p4iMjpOP9TrnKT5R3ANBH5ecBp/wYqVbUiUus0Q0FVPwU2icglIhKrqh/j/Po9Exgd3ujCQ0SS3KefAevt3nzH7XQRLyIpwDxgDXCSiHRR1Urgf4GRInJNGMNsVETWV7UUVa0QkecABe4UkWOASqATsDWswYWBiJwAPAOco6qfiUgmUACcD7wpItU41WcnAMNEJE1Vd4Qt4DAQkeOBBKBcVT/D+YM+AdguIgtV9SMReQH4gYi8p6o1YQw3pERkIjBIRB7B+TtajFMFYvfmu04XH+GUsm/H+Vu7yTksC1T1SxF5HYi4Ktc2nQgAVHWHiPwNWIVTj1kBXKmq28IbWVgUA9VAFxHJAF4EaoCVwBPAMJw2leHAtVGYBCYBfwHeBzqJyEZV/bGI3IGTLLvj/HErzv9HUVNacu/N74GbVbXcfe0p4DbgPKL03rhVp9l81+liNXA1TkI4EXgEuAynVmIZcClwcjhibU6b7j7akDuOQKO5EVREBuM0nPuB+4C/Az/AqSr7varmR2lJwAc8B7ypqs+4PcvmAKtVdYqIXAmcgfNHnwFMVtWl4Ys4dESkP/Am8DtVneH+iOgElKnqhmi+N1D//85jOH9PW1RVReRW4FbgBFUtEJGTgL7APFVdG8ZwGxVVicA43D/sU1T1rwGvzQHuVNUlkdzf2UtuO8kWVX0m4LWPgE9V9VZ3fyBOI+n2MIUZciIyDLgOWIJTlXgbTukyC1ikqj93z4uqeyMivXA6FKwDHgUWq+ofA47fgfPlf8O+UlSkauuNxaYRqrqqQRK4CGdZvc3u8ahJAm43yH02Az8XkZyA184FckRkAICqfh5FX3R9AFR1MU5p6Vjgr8BLOFUcVwPDRWSse1403Zuzgf8Af8IpCTwH3CAidwac9gJOVWxF6CM8NJYIopg7qGwKTi+iydHWbuL+MS9zGzhR1Wdxqs0W7ksGqlqE88ecHLZAw6CRe7MQeB64TVWnB4xDyQeialSx2+niT8DVqjoOp5p1JE6ngh+JyN1uaeFk4DigQ5hCDZpVDUUxt6FrHPCtqn4Z7nhCSZx5lV7G+VV3AhCvqpe5x36NUxJ4FKekdCVwpqquD1O4IdXIvfGr6uXuscSAxuKLcLoff09VN4Yr3lBzE0EfVX3K3c/CmbrmLBE5CrgbpxQwEqfTxedhCzZIlghM1BKRrsBunO6i04HqgGRwAdAZpyfVQ6r6RdgCDYNG7k2lql4RcPxqnF4y10bhvfEByaq6233eBXgd58fCVhHpgVPNmKyqu8IZa7AsERgDuD1hZgBVqnqZiBwL7I2mX7pNCbg35ap6pYj0A04B3lLVdeGNLrzcuYMSgNdUdbzbg+ok4JZIbyAOZInAGJc7wO4BnOoQH3CyqhaEN6rI0ODeCDBOVaNuUGZT3DEVW4HTcaZsifjqoEBtfkCZMcFS1SIRWQFMAiZYEvhOI/fGkgD17WxxOKWAOGC8qn4d3qgOnSUCY1ziTKN8JnB6a/tF5zW7N41zu1pXuR0MFrXGJABWNWTMfkQkwZ0t0jRg96ZprX0QpiUCY4yJcjagzBhjopwlAmOMiXKWCIwxJspZIjCtlrsi1PsislpEVorIzQHHLnZfqxOR4Q3eN0hEPnaPfy4iCSGIda/72FVEXjrIubfIdyuBGeM5ayw2rZaIdAG6uFNnt8NZMet8VV3ljn6tAx7HmSgtz31PLM50ylep6nJ31OxOVa09jM+PDXYVLhHZq6opQZ67ARjuTngXbCy+w/k3GAM2jsC0Yu6gpq3u8z0ishrohrMe82oAZ7zPfk4HVqjqcvd9xY1d2/0ynokzlQLA5aq61h1BWgIMBZaIyKM4UzNn4SxOfr27JGEu8C+cv7G3Aq7bE3hDVQe489T8AZiIs6LX33BG7XYF3heRIlU9RUQuA37hHnszYP7/vcCD7vt/6s4Yei7OqnNvq+pth3A7TRSzRGDaBPcLdijw6UFO7QOouxBPFvBC4GIiDexW1ZEiMhl4CDg74BqnqWqtiLwLTFPVr8VZ7/hR4FTgYeAxVX1aRG5s4vpTgVxgqKrWiEi6qpaIyE9wFg4qcid/+wPO5Hc7gLdF5HxVfRVnauwvVPWXIpKOs9rcMe4KWR0Och+MqWdtBKbVE5EUnGmTb1HV3Qc5PRYYA1zhPl4gIuObOPf5gMfRAa+/6CaBFJy5d14UZz3ax3FmogRnvdp973+Gxp0GTN9XvaSqJY2cMwJnecNC97zngLHusVqcfzc4M4VWAE+IyIU4pRNjgmKJwLRqIhKH82X4nKr+J4i3FADzVbVIVcuA2TiLhzRGm3he6j7G4LQvDAnY+jXxnkbDD/KcplTsaxdwk8RInHtxPgHVUcYcjCUC02q5E379HWeB+QeDfNscYJCIJLkNx+OAVU2c+/2Ax48bHnRLH+tF5OJ98YjIYPfwQpzlHMEpfTTmbWCaGwdu9Q7AHqCd+/xTYJyIZLptCpcB8xteyC2dtFfV2cAtwJAmPtOYA1giMK3ZicBVwKkisszdzgRnYRkRKcCp0nnTbRNAVXfgNLAuApYBS1T1zSauHy8inwI3A7c2cc4VwHUishxYCZznvn4zcKOILALaN/HeJ4BNwAr3/Ze7r88A/isi77sN4ncC7wPL3Xhfa+Ra7YA33BlC5zcTrzEHsO6jxjTicLpwGtNaWYnAGGOinJUIjDEmylmJwBhjopwlAmOMiXKWCIwxJspZIjDGmChnicAYY6KcJQJjjIly/x/yYewui9diEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Visualize the Fisher Score\n",
    "plt.plot(fs_df['fisherscore'].values.squeeze())\n",
    "plt.axvline(x=20, linestyle='dashed', color='red')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(str(fs_df.shape[0]) + ' predictors')\n",
    "plt.ylabel('Fisher Score')\n",
    "plt.legend(['Fisher Score', 'Top20'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Check how AUC change when add more variables: Top n vars\n",
    "fs_scores = []\n",
    "top_n_vars = 50\n",
    "for i in range(1, top_n_vars+1):\n",
    "    if i % 100 == 0: print('Added # top vars :', i)\n",
    "    top_n_predictors = fs_df['predictor'][:i]\n",
    "    clf = LogisticRegression()\n",
    "    fs_scores.append(cross_validate(clf, train[top_n_predictors], train[target_var].values.squeeze(),\n",
    "                                    scoring='roc_auc', cv=5, verbose=0, n_jobs=-1, return_train_score=True))\n",
    "\n",
    "# How the AUC curve looks like when adding top vars\n",
    "plt.plot([s['train_score'].mean() for s in fs_scores], color='blue')\n",
    "plt.plot([s['test_score'].mean() for s in fs_scores], color='red')\n",
    "plt.xlabel('# vars')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected # vars : 50\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['nr.employed', 'euribor3m', 'emp.var.rate', 'pdays', 'pdays_bin_4',\n",
       "       'poutcome_3.0', 'previous', 'poutcome_2.0', 'emp.var.rate_bin_14',\n",
       "       'nr.employed_bin_16', 'pdays_bin_3', 'cons.price.idx_bin_21',\n",
       "       'contact_2.0', 'nr.employed_bin_13', 'emp.var.rate_bin_13',\n",
       "       'cons.conf.idx_bin_20', 'contact_1.0', 'previous_bin_6',\n",
       "       'nr.employed_bin_8', 'cons.price.idx', 'cons.conf.idx_bin_23',\n",
       "       'nr.employed_bin_9', 'emp.var.rate_bin_5', 'month_7.0',\n",
       "       'default_remap_4', 'default_2.0', 'emp.var.rate_bin_8',\n",
       "       'nr.employed_bin_6', 'nr.employed_bin_7', 'cons.price.idx_bin_25',\n",
       "       'cons.conf.idx_bin_18', 'cons.price.idx_bin_5', 'default_1.0',\n",
       "       'cons.conf.idx_bin_17', 'emp.var.rate_bin_9', 'previous_bin_5',\n",
       "       'month_9.0', 'cons.price.idx_bin_4', 'euribor3m_bin_60',\n",
       "       'cons.conf.idx_bin_27', 'month_10.0', 'month_6.0',\n",
       "       'euribor3m_bin_7', 'cons.price.idx_bin_17', 'age_bin_76',\n",
       "       'euribor3m_bin_4', 'cons.conf.idx_bin_21', 'euribor3m_bin_14',\n",
       "       'cons.conf.idx_bin_11', 'cons.conf.idx_bin_13'], dtype=object)"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Select the top variables based on Fisher Score\n",
    "n_top_fs_vars = 50  # Top FS vars\n",
    "top_fs_vars = fs_df['predictor'].values[:n_top_fs_vars]\n",
    "print(\"Selected # vars :\", len(top_fs_vars))\n",
    "top_fs_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 218)\n",
      "(4000, 218)\n",
      "(10000, 217)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(validation.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Subset the train, validation, and test sets to keep only the features selected through the fisher score\n",
    "\n",
    "X_train = train[top_fs_vars]\n",
    "X_validation = validation[top_fs_vars]\n",
    "X_test = test[top_fs_vars]\n",
    "X_full = pd.concat([X_train, X_validation], axis=0)\n",
    "\n",
    "test_id = test[id_var]\n",
    "\n",
    "\n",
    "y_train = train[target_var]\n",
    "y_validation = validation[target_var]\n",
    "y_full = pd.concat([y_train, y_validation], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Modeling Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the models\n",
    "\n",
    "tree         = DecisionTreeClassifier()\n",
    "logistic     = LogisticRegression(solver = \"lbfgs\", max_iter = 500)\n",
    "randomForest = RandomForestClassifier(n_estimators = 100)\n",
    "boostedTree  = GradientBoostingClassifier()\n",
    "svm          = SVC(gamma = \"scale\", probability = True)\n",
    "neuralNet    = MLPClassifier()\n",
    "neighbors    = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Decision Tree\"         :tree,\n",
    "          \"Logistic Regression\"     :logistic,\n",
    "          \"Random Forest\" :randomForest,\n",
    "          \"Boosted Tree\"  :boostedTree,\n",
    "          \"SVM\"          :svm,\n",
    "          \"NeuralNet\"    :neuralNet,\n",
    "          \"KNN\"    :neighbors\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the models on the train set\n",
    "\n",
    "for model in models:\n",
    "    models[model].fit(X_train, y_train.values.ravel())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on the train and validation to evaluate and compare\n",
    "\n",
    "performances = {}\n",
    "\n",
    "for model in models:\n",
    "    train_pred          = models[model].predict(X_train)\n",
    "    validation_pred     = models[model].predict(X_validation)\n",
    "    train_prob          = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    validation_prob     = pd.DataFrame(models[model].predict_proba(X_validation))[1]\n",
    "    train_accuracy      = accuracy_score(y_train, train_pred)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_pred)\n",
    "    train_auc           = roc_auc_score(np.array(y_train),np.array(train_prob))\n",
    "    validation_auc      = roc_auc_score(np.array(y_validation),np.array(validation_prob))\n",
    "    train_f1            = f1_score(y_train, train_pred)\n",
    "    validation_f1       = f1_score(y_validation, validation_pred)\n",
    "    \n",
    "    performances[model] = {\"Validation Accuracy\": validation_accuracy, \"Train Accuracy\": train_accuracy, \"Validation AUC\": validation_auc, \"Train AUC\": train_auc, \"Validation F1\": validation_f1, \"Train F1\": train_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Validation F1</th>\n",
       "      <th>Train F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.88975</td>\n",
       "      <td>0.929312</td>\n",
       "      <td>0.684741</td>\n",
       "      <td>0.887035</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.565501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.89625</td>\n",
       "      <td>0.901687</td>\n",
       "      <td>0.788269</td>\n",
       "      <td>0.789066</td>\n",
       "      <td>0.323002</td>\n",
       "      <td>0.353473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.89200</td>\n",
       "      <td>0.929312</td>\n",
       "      <td>0.768827</td>\n",
       "      <td>0.875760</td>\n",
       "      <td>0.393258</td>\n",
       "      <td>0.593312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boosted Tree</th>\n",
       "      <td>0.89525</td>\n",
       "      <td>0.905563</td>\n",
       "      <td>0.795651</td>\n",
       "      <td>0.806551</td>\n",
       "      <td>0.325282</td>\n",
       "      <td>0.394389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.89600</td>\n",
       "      <td>0.897938</td>\n",
       "      <td>0.721191</td>\n",
       "      <td>0.721484</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.323249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNet</th>\n",
       "      <td>0.89575</td>\n",
       "      <td>0.898375</td>\n",
       "      <td>0.790384</td>\n",
       "      <td>0.790185</td>\n",
       "      <td>0.324149</td>\n",
       "      <td>0.341167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.89275</td>\n",
       "      <td>0.910250</td>\n",
       "      <td>0.728337</td>\n",
       "      <td>0.791452</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>0.473993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Validation Accuracy  Train Accuracy  Validation AUC  \\\n",
       "Decision Tree                    0.88975        0.929312        0.684741   \n",
       "Logistic Regression              0.89625        0.901687        0.788269   \n",
       "Random Forest                    0.89200        0.929312        0.768827   \n",
       "Boosted Tree                     0.89525        0.905563        0.795651   \n",
       "SVM                              0.89600        0.897938        0.721191   \n",
       "NeuralNet                        0.89575        0.898375        0.790384   \n",
       "KNN                              0.89275        0.910250        0.728337   \n",
       "\n",
       "                     Train AUC  Validation F1  Train F1  \n",
       "Decision Tree         0.887035       0.336842  0.565501  \n",
       "Logistic Regression   0.789066       0.323002  0.353473  \n",
       "Random Forest         0.875760       0.393258  0.593312  \n",
       "Boosted Tree          0.806551       0.325282  0.394389  \n",
       "SVM                   0.721484       0.315789  0.323249  \n",
       "NeuralNet             0.790185       0.324149  0.341167  \n",
       "KNN                   0.791452       0.384505  0.473993  "
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(performances).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Hyperparameter Tuning of Selected Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "MLPClassifier()\n",
      "Wall time: 6min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "model = MLPClassifier()\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (100,100,100), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "gs_nn = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=1)\n",
    "gs_nn.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(gs_nn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NeuralNet</th>\n",
       "      <td>0.789121</td>\n",
       "      <td>0.886437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789024</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train AUC  Train Accuracy  Train F1  Validation AUC  \\\n",
       "NeuralNet   0.789121        0.886437       0.0        0.789024   \n",
       "\n",
       "           Validation Accuracy  Validation F1  \n",
       "NeuralNet               0.8865            0.0  "
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPClassifier(activation =  'relu', alpha =  0.0001, hidden_layer_sizes =  (100,), learning_rate =  'constant', solver =  'adam')\n",
    "\n",
    "models = {\"NeuralNet\" : nn\n",
    "         }\n",
    "for model in models:\n",
    "    models[model].fit(X_train, y_train.values.ravel())\n",
    "performances = {}\n",
    "for model in models:\n",
    "    train_pred          = models[model].predict(X_train)\n",
    "    validation_pred     = models[model].predict(X_validation)\n",
    "    train_prob          = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    validation_prob     = pd.DataFrame(models[model].predict_proba(X_validation))[1]\n",
    "    train_accuracy      = accuracy_score(y_train, train_pred)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_pred)\n",
    "    train_auc           = roc_auc_score(np.array(y_train),np.array(train_prob))\n",
    "    validation_auc      = roc_auc_score(np.array(y_validation),np.array(validation_prob))\n",
    "    train_f1            = f1_score(y_train, train_pred)\n",
    "    validation_f1       = f1_score(y_validation, validation_pred)\n",
    "    performances[model] = {\"Validation Accuracy\": validation_accuracy, \"Train Accuracy\": train_accuracy, \"Validation AUC\": validation_auc, \"Train AUC\": train_auc, \"Validation F1\": validation_f1, \"Train F1\": train_f1}\n",
    "pd.DataFrame(performances).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (150, 100, 50)}\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "model = MLPClassifier()\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (100,100,100), (150, 100, 50)],\n",
    "    'alpha': [0.0001, 0.01, 0.05, 0.09]\n",
    "}\n",
    "gs_nn = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=1)\n",
    "gs_nn.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(gs_nn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NeuralNet</th>\n",
       "      <td>0.788526</td>\n",
       "      <td>0.900375</td>\n",
       "      <td>0.321702</td>\n",
       "      <td>0.790685</td>\n",
       "      <td>0.89725</td>\n",
       "      <td>0.309244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train AUC  Train Accuracy  Train F1  Validation AUC  \\\n",
       "NeuralNet   0.788526        0.900375  0.321702        0.790685   \n",
       "\n",
       "           Validation Accuracy  Validation F1  \n",
       "NeuralNet              0.89725       0.309244  "
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPClassifier(alpha =  0.0001, hidden_layer_sizes =  (150, 100, 50))\n",
    "\n",
    "models = {\"NeuralNet\" : nn\n",
    "         }\n",
    "for model in models:\n",
    "    models[model].fit(X_train, y_train.values.ravel())\n",
    "performances = {}\n",
    "for model in models:\n",
    "    train_pred          = models[model].predict(X_train)\n",
    "    validation_pred     = models[model].predict(X_validation)\n",
    "    train_prob          = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    validation_prob     = pd.DataFrame(models[model].predict_proba(X_validation))[1]\n",
    "    train_accuracy      = accuracy_score(y_train, train_pred)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_pred)\n",
    "    train_auc           = roc_auc_score(np.array(y_train),np.array(train_prob))\n",
    "    validation_auc      = roc_auc_score(np.array(y_validation),np.array(validation_prob))\n",
    "    train_f1            = f1_score(y_train, train_pred)\n",
    "    validation_f1       = f1_score(y_validation, validation_pred)\n",
    "    performances[model] = {\"Validation Accuracy\": validation_accuracy, \"Train Accuracy\": train_accuracy, \"Validation AUC\": validation_auc, \"Train AUC\": train_auc, \"Validation F1\": validation_f1, \"Train F1\": train_f1}\n",
    "pd.DataFrame(performances).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (15,), 'solver': 'adam'}\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "model = MLPClassifier()\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(15,), (45,2,11,), (100,), (2,)],\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    'alpha': [0.0001, 0.001]\n",
    "}\n",
    "gs_nn = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=1)\n",
    "gs_nn.fit(X_train, y_train.values.ravel())\n",
    "print(gs_nn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NeuralNet</th>\n",
       "      <td>0.78886</td>\n",
       "      <td>0.886437</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789465</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train AUC  Train Accuracy  Train F1  Validation AUC  \\\n",
       "NeuralNet    0.78886        0.886437       0.0        0.789465   \n",
       "\n",
       "           Validation Accuracy  Validation F1  \n",
       "NeuralNet               0.8865            0.0  "
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPClassifier(alpha =  0.001, hidden_layer_sizes =  (15,), solver =  'adam')\n",
    "\n",
    "models = {\"NeuralNet\" : nn\n",
    "         }\n",
    "for model in models:\n",
    "    models[model].fit(X_train, y_train.values.ravel())\n",
    "performances = {}\n",
    "for model in models:\n",
    "    train_pred          = models[model].predict(X_train)\n",
    "    validation_pred     = models[model].predict(X_validation)\n",
    "    train_prob          = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    validation_prob     = pd.DataFrame(models[model].predict_proba(X_validation))[1]\n",
    "    train_accuracy      = accuracy_score(y_train, train_pred)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_pred)\n",
    "    train_auc           = roc_auc_score(np.array(y_train),np.array(train_prob))\n",
    "    validation_auc      = roc_auc_score(np.array(y_validation),np.array(validation_prob))\n",
    "    train_f1            = f1_score(y_train, train_pred)\n",
    "    validation_f1       = f1_score(y_validation, validation_pred)\n",
    "    performances[model] = {\"Validation Accuracy\": validation_accuracy, \"Train Accuracy\": train_accuracy, \"Validation AUC\": validation_auc, \"Train AUC\": train_auc, \"Validation F1\": validation_f1, \"Train F1\": train_f1}\n",
    "pd.DataFrame(performances).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 100, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "Wall time: 1min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "model = LogisticRegression()\n",
    "parameters = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "    'solver':  ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter': [100,300]\n",
    "}\n",
    "gs_lr = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=1)\n",
    "gs_lr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(gs_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logreg</th>\n",
       "      <td>0.795268</td>\n",
       "      <td>0.90175</td>\n",
       "      <td>0.360976</td>\n",
       "      <td>0.793759</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>0.334405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Train AUC  Train Accuracy  Train F1  Validation AUC  \\\n",
       "Logreg   0.795268         0.90175  0.360976        0.793759   \n",
       "\n",
       "        Validation Accuracy  Validation F1  \n",
       "Logreg               0.8965       0.334405  "
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 100, penalty = 'none', solver = 'newton-cg')\n",
    "\n",
    "models = {\"Logreg\" : lr\n",
    "         }\n",
    "for model in models:\n",
    "    models[model].fit(X_train, y_train.values.ravel())\n",
    "performances = {}\n",
    "for model in models:\n",
    "    train_pred          = models[model].predict(X_train)\n",
    "    validation_pred     = models[model].predict(X_validation)\n",
    "    train_prob          = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    validation_prob     = pd.DataFrame(models[model].predict_proba(X_validation))[1]\n",
    "    train_accuracy      = accuracy_score(y_train, train_pred)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_pred)\n",
    "    train_auc           = roc_auc_score(np.array(y_train),np.array(train_prob))\n",
    "    validation_auc      = roc_auc_score(np.array(y_validation),np.array(validation_prob))\n",
    "    train_f1            = f1_score(y_train, train_pred)\n",
    "    validation_f1       = f1_score(y_validation, validation_pred)\n",
    "    performances[model] = {\"Validation Accuracy\": validation_accuracy, \"Train Accuracy\": train_accuracy, \"Validation AUC\": validation_auc, \"Train AUC\": train_auc, \"Validation F1\": validation_f1, \"Train F1\": train_f1}\n",
    "pd.DataFrame(performances).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "{'max_iter': 300, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "model = LogisticRegression()\n",
    "parameters = {\n",
    "    'penalty': ['l2', 'l1'],\n",
    "    'solver':  ['liblinear', 'saga'],\n",
    "    'max_iter': [100,300, 700]\n",
    "}\n",
    "gs_lr = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=1)\n",
    "gs_lr.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(gs_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logreg</th>\n",
       "      <td>0.793226</td>\n",
       "      <td>0.901312</td>\n",
       "      <td>0.355773</td>\n",
       "      <td>0.794583</td>\n",
       "      <td>0.89475</td>\n",
       "      <td>0.313214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Train AUC  Train Accuracy  Train F1  Validation AUC  \\\n",
       "Logreg   0.793226        0.901312  0.355773        0.794583   \n",
       "\n",
       "        Validation Accuracy  Validation F1  \n",
       "Logreg              0.89475       0.313214  "
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 300, penalty = 'l1', solver = 'liblinear')\n",
    "\n",
    "models = {\"Logreg\" : lr\n",
    "         }\n",
    "for model in models:\n",
    "    models[model].fit(X_train, y_train.values.ravel())\n",
    "performances = {}\n",
    "for model in models:\n",
    "    train_pred          = models[model].predict(X_train)\n",
    "    validation_pred     = models[model].predict(X_validation)\n",
    "    train_prob          = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    validation_prob     = pd.DataFrame(models[model].predict_proba(X_validation))[1]\n",
    "    train_accuracy      = accuracy_score(y_train, train_pred)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_pred)\n",
    "    train_auc           = roc_auc_score(np.array(y_train),np.array(train_prob))\n",
    "    validation_auc      = roc_auc_score(np.array(y_validation),np.array(validation_prob))\n",
    "    train_f1            = f1_score(y_train, train_pred)\n",
    "    validation_f1       = f1_score(y_validation, validation_pred)\n",
    "    performances[model] = {\"Validation Accuracy\": validation_accuracy, \"Train Accuracy\": train_accuracy, \"Validation AUC\": validation_auc, \"Train AUC\": train_auc, \"Validation F1\": validation_f1, \"Train F1\": train_f1}\n",
    "pd.DataFrame(performances).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.78667417 0.5293832         nan 0.78934423 0.48670373\n",
      "        nan 0.78764853 0.55964971        nan 0.78834864 0.5\n",
      " 0.526773   0.78710625 0.57479106 0.55752012 0.78840992 0.51376741\n",
      "        nan 0.78846339 0.61228407        nan 0.78846311 0.56735382\n",
      "        nan 0.78821969 0.59881467        nan 0.78940469 0.51547767\n",
      "        nan 0.78735987 0.5               nan 0.78739158 0.54874034\n",
      "        nan 0.7874578  0.51521648        nan 0.787845   0.5218835\n",
      "        nan 0.78767824 0.50121752        nan 0.78745485 0.5649817\n",
      " 0.57964836 0.78577636 0.56933924 0.57777567 0.78957351 0.61347357\n",
      "        nan 0.78556143 0.51184632        nan 0.78725406 0.55662876\n",
      "        nan 0.78854814 0.52706754        nan 0.7855311  0.55895226\n",
      "        nan 0.7207158  0.56367325        nan 0.78644383 0.54390467\n",
      "        nan 0.78692066 0.57120929        nan 0.78420671 0.58632548\n",
      "        nan 0.78745503 0.53846017        nan 0.78691032 0.5\n",
      " 0.60002164 0.78573788 0.5327563  0.55943425 0.78819735 0.49281913\n",
      "        nan 0.78738085 0.66514284        nan 0.78839567 0.5447914\n",
      "        nan 0.78848927 0.54358606        nan 0.78915635 0.66290905\n",
      "        nan 0.78880314 0.57557932        nan 0.78865428 0.55055722\n",
      "        nan 0.78879442 0.52407403        nan 0.78857157 0.61090882\n",
      "        nan 0.78566673 0.50717639        nan 0.78893277 0.55338195\n",
      " 0.57964836 0.78830371 0.5569026  0.60002164 0.78854442 0.50786696\n",
      "        nan 0.78842778 0.59471242        nan 0.6619938  0.51488276\n",
      "        nan 0.70903728 0.56014987        nan 0.72182205 0.50561524\n",
      "        nan 0.78800168 0.617123          nan 0.78582349 0.54419948\n",
      "        nan 0.78533056 0.57251912        nan 0.78583542 0.56125984\n",
      "        nan 0.78770243 0.56977766        nan 0.78817753 0.5608388\n",
      " 0.53391331 0.78851808 0.48732803 0.56287481 0.78903588 0.59261304\n",
      "        nan 0.78781392 0.53511057        nan 0.78877485 0.59241383\n",
      "        nan 0.78903872 0.54572614        nan 0.78697247 0.50916209\n",
      "        nan 0.78904401 0.61323878        nan 0.78651046 0.55180041\n",
      "        nan 0.78786026 0.52265305        nan 0.78741535 0.57527151\n",
      "        nan 0.7876284  0.55449835        nan 0.78821856 0.50926029\n",
      " 0.58121623 0.78836892 0.56716106 0.60002164 0.78814388 0.52648386\n",
      "        nan 0.77198686 0.62191619        nan 0.78755817 0.6682698\n",
      "        nan 0.78727815 0.59288081        nan 0.7865223  0.55979981\n",
      "        nan 0.78705674 0.51945151        nan 0.78780495 0.61626046\n",
      " 0.5207193  0.45767783 0.63529956 0.57055621 0.47453108 0.53204366\n",
      " 0.56278188 0.50433815 0.47312201 0.50472229 0.45834694 0.47270859\n",
      " 0.41897193 0.45660019 0.5        0.58221099 0.50606832 0.53230476\n",
      " 0.4818483  0.4508574  0.54530133 0.59787647 0.45033314 0.62743761\n",
      " 0.53043867 0.45165288 0.57476445 0.48403222 0.44978943 0.52932208\n",
      " 0.4650621  0.4511111  0.45859178 0.43004537 0.45091716 0.57851109\n",
      " 0.51547182 0.51121882 0.4882392  0.4479064  0.49037456 0.45199305\n",
      " 0.46245891 0.48546669 0.51815525 0.51092315 0.5243551  0.53143806\n",
      " 0.54470524 0.53810941 0.44608358 0.57749784 0.52273177 0.57642287\n",
      " 0.5        0.4897109  0.5        0.5        0.49881929 0.5\n",
      " 0.47959347 0.49606896 0.5        0.53037095 0.47173793 0.5\n",
      " 0.5        0.41688806 0.5        0.51885274 0.48014746 0.5\n",
      " 0.50371179 0.45066446 0.63934773 0.52171099 0.45089624 0.54735777\n",
      " 0.50476168 0.45122617 0.59562763 0.52820004 0.45905701 0.52025555\n",
      " 0.4893667  0.45460298 0.51529315 0.58260389 0.45269201 0.48808757\n",
      " 0.62252659 0.4517659  0.56858246 0.46679031 0.45104587 0.55841717\n",
      " 0.47699011 0.45239856 0.64758629 0.56466983 0.45125401 0.56125243\n",
      " 0.53570434 0.45356865 0.54593228 0.66407551 0.45327673 0.4968006\n",
      " 0.5878608  0.53787392 0.46079557 0.4899894  0.52001357 0.49482454\n",
      " 0.55226946 0.51259974 0.51039437 0.51729993 0.54744318 0.56655894\n",
      " 0.64897578 0.525301   0.53551075 0.49792285 0.51985192 0.52169637\n",
      " 0.5        0.50620046 0.53901305 0.49674482 0.53870147 0.4805208\n",
      " 0.5        0.51308799 0.51262917 0.49854785 0.50118647 0.52019274\n",
      " 0.5        0.53480532 0.5        0.5        0.55573161 0.5\n",
      " 0.49156555 0.45152621 0.47588314 0.5210254  0.46762859 0.61963244\n",
      " 0.57002534 0.45151213 0.54058652 0.4565559  0.45299341 0.48614229\n",
      " 0.48916182 0.45188894 0.5719564  0.56134846 0.4775907  0.61275106\n",
      " 0.52137798 0.45220163 0.47036708 0.46895542 0.45391465 0.54993998\n",
      " 0.38027079 0.4512897  0.58600896 0.55323409 0.45384399 0.55815993\n",
      " 0.46278821 0.45220528 0.53683726 0.53597948 0.49894198 0.48924154\n",
      " 0.46574672 0.45331851 0.63269611 0.4506975  0.45137417 0.5061715\n",
      " 0.52227536 0.45546145 0.59381705 0.52121437 0.492588   0.49258752\n",
      " 0.65275219 0.45133294 0.53310464 0.60388564 0.48041765 0.56538998\n",
      " 0.47120898 0.50594851 0.50018455 0.5        0.48107488 0.51834142\n",
      " 0.5        0.49954368 0.5        0.5        0.50352807 0.5604585\n",
      " 0.51882274 0.52042655 0.50131877 0.48165858 0.50051413 0.49614056\n",
      " 0.54083819 0.40458158 0.5489306  0.57969955 0.46447342 0.57393424\n",
      " 0.53935281 0.36898514 0.54071731 0.526482   0.40874241 0.56283562\n",
      " 0.49122052 0.28605004 0.54105139 0.55740082 0.52023269 0.55954266\n",
      " 0.45098737 0.40947138 0.53651102 0.49419323 0.44999755 0.53595568\n",
      " 0.56400301 0.44791297 0.61715492 0.5600611  0.56909331 0.61179365\n",
      " 0.52156713 0.44941502 0.50998355 0.408377   0.44853929 0.61588253\n",
      " 0.44657745 0.45723611 0.60209444 0.47036274 0.46676322 0.5737659\n",
      " 0.60470441 0.46018286 0.62629681 0.5997511  0.4588429  0.58487025\n",
      " 0.56577998 0.47243808 0.59949791 0.5511642  0.45652566 0.50599537\n",
      " 0.52025555 0.47398709 0.53467797 0.51834142 0.42876335 0.5\n",
      " 0.5        0.44347593 0.51834142 0.5        0.42180885 0.52224597\n",
      " 0.5        0.34706859 0.5        0.5        0.40907456 0.5\n",
      " 0.54051776 0.48967572 0.58608395 0.56082374 0.50275914 0.54105139\n",
      " 0.53859307 0.50411904 0.59999045 0.55740239 0.38183934 0.5554456\n",
      " 0.55691231 0.41116004 0.55939281 0.52073819 0.47366773 0.52286475\n",
      " 0.53268295 0.5080526  0.61656809 0.61608396 0.46111804 0.54339467\n",
      " 0.54022755 0.45351145 0.54593439 0.57751582 0.44937427 0.53674148\n",
      " 0.49751396 0.44753384 0.61149914 0.48446685 0.46332907 0.60011325\n",
      " 0.53576802 0.45479118 0.48458518 0.59837228 0.45571793 0.60674354\n",
      " 0.58060635 0.46545879 0.62720824 0.56018235 0.52552427 0.5681638\n",
      " 0.59013262 0.4647782  0.50750774 0.52526824 0.46418768 0.57862397\n",
      " 0.5        0.45488468 0.5        0.5        0.43979306 0.5\n",
      " 0.5        0.44400734 0.5        0.5        0.39567883 0.5\n",
      " 0.5        0.5        0.5        0.5        0.38969843 0.5\n",
      " 0.56102198 0.50171104 0.54058739 0.53921729 0.41109069 0.43736308\n",
      " 0.59251551 0.37666526 0.56776027 0.56130684 0.51869297 0.57954871\n",
      " 0.48525062 0.45057237 0.5546427  0.50024186 0.45097949 0.51834142\n",
      " 0.50876653 0.42209595 0.57037979 0.53992218 0.48515413 0.61529063\n",
      " 0.56292693 0.44962332 0.58140275 0.51661262 0.45515942 0.58812788\n",
      " 0.58912282 0.45162112 0.62269137 0.45528226 0.457671   0.59437808\n",
      " 0.59728508 0.45335535 0.51562031 0.6534876  0.44943554 0.6257455\n",
      " 0.52919144 0.45547955 0.54629646 0.53592665 0.45430655 0.55176112\n",
      " 0.46574674 0.48259313 0.5812246  0.58948362 0.46398638 0.56031823\n",
      " 0.51883403 0.44871465 0.5        0.5099894  0.4912999  0.5\n",
      " 0.5        0.51834142 0.5387147  0.5        0.34792187 0.53906447\n",
      " 0.5        0.38923628 0.52037328 0.5        0.29026535 0.5\n",
      " 0.5        0.78762409 0.57667111 0.5        0.78868125 0.51800841\n",
      " 0.5        0.78543689 0.5        0.5        0.78680264 0.5\n",
      " 0.5        0.78528778 0.5        0.5        0.78664892 0.49843505\n",
      " 0.5        0.55485233 0.514112   0.5        0.62153872 0.5\n",
      " 0.5        0.56017838 0.55615268 0.5        0.55482226 0.5\n",
      " 0.5        0.61505585 0.55851937 0.5        0.61178907 0.5\n",
      " 0.5        0.78805783 0.50941472 0.5        0.78891517 0.59863418\n",
      " 0.5        0.78834235 0.61069758 0.5        0.78864647 0.55881779\n",
      " 0.5        0.78883548 0.5223002  0.5        0.7891988  0.5\n",
      " 0.5        0.60942504 0.5023725  0.5        0.66313661 0.5\n",
      " 0.5        0.62881075 0.5        0.5        0.60717261 0.55497564\n",
      " 0.5        0.67270349 0.55634031 0.5        0.67737084 0.5\n",
      " 0.5        0.78471613 0.60217352 0.5        0.78751195 0.60343781\n",
      " 0.5        0.78691307 0.51037898 0.5        0.78554486 0.47671741\n",
      " 0.5        0.78954338 0.51920195 0.5        0.78561848 0.49418762\n",
      " 0.5        0.61437471 0.5        0.5        0.6723022  0.55881223\n",
      " 0.5        0.61674473 0.60563707 0.5        0.61698873 0.5\n",
      " 0.5        0.56094497 0.55388747 0.5        0.5        0.55526557\n",
      " 0.5        0.78816424 0.56419154 0.5        0.7878343  0.61686133\n",
      " 0.5        0.78916969 0.52016773 0.5        0.78722964 0.52884782\n",
      " 0.51878977 0.78905081 0.56502742 0.5        0.78867077 0.50047941\n",
      " 0.5        0.72572328 0.5        0.5        0.56915108 0.5\n",
      " 0.5        0.61961479 0.57495238 0.5        0.62778056 0.55613476\n",
      " 0.5        0.78726676 0.49950368 0.5        0.58447884 0.55176837\n",
      " 0.5        0.77790833 0.59969326 0.5        0.78935802 0.63048876\n",
      " 0.5        0.78759171 0.54465035 0.5        0.78703995 0.55950765\n",
      " 0.5        0.78494802 0.5        0.5        0.78584217 0.60447234\n",
      " 0.5        0.61718057 0.61649066 0.5        0.67763345 0.5\n",
      " 0.5        0.5        0.50772691 0.5        0.61424444 0.56013644\n",
      " 0.5        0.67143044 0.54527799 0.5        0.55415732 0.5\n",
      " 0.5        0.7870212  0.52794036 0.5        0.78796537 0.5136197\n",
      " 0.5        0.78825715 0.55512375 0.5        0.78675207 0.57431189\n",
      " 0.54040453 0.78794256 0.56662989 0.5        0.78895778 0.51012934\n",
      " 0.5        0.62479705 0.5        0.5        0.68822247 0.5\n",
      " 0.5        0.68714554 0.5        0.5        0.63729045 0.54827139\n",
      " 0.5        0.6907836  0.52227154 0.5        0.65900946 0.58730763]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'identity', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'learning_rate': 'invscaling', 'max_iter': 500, 'solver': 'adam'}\n",
      "Wall time: 1h 10min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "model = MLPClassifier()\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(15,), (45,2,11,), (100,), (2,5,)],\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'learning_rate': ['constant','adaptive', 'invscaling'],\n",
    "    'max_iter' : [200, 500]\n",
    "}\n",
    "gs_nn = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=1)\n",
    "gs_nn.fit(X_train, y_train.values.ravel())\n",
    "print(gs_nn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NeuralNet</th>\n",
       "      <td>0.789745</td>\n",
       "      <td>0.89775</td>\n",
       "      <td>0.383572</td>\n",
       "      <td>0.788734</td>\n",
       "      <td>0.89175</td>\n",
       "      <td>0.348872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train AUC  Train Accuracy  Train F1  Validation AUC  \\\n",
       "NeuralNet   0.789745         0.89775  0.383572        0.788734   \n",
       "\n",
       "           Validation Accuracy  Validation F1  \n",
       "NeuralNet              0.89175       0.348872  "
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPClassifier(activation = 'identity', alpha =  0.0001, hidden_layer_sizes =  (100,), learning_rate = 'invscaling', max_iter = 500, solver =  'adam')\n",
    "\n",
    "models = {\"NeuralNet\" : nn\n",
    "         }\n",
    "for model in models:\n",
    "    models[model].fit(X_train, y_train.values.ravel())\n",
    "performances = {}\n",
    "for model in models:\n",
    "    train_pred          = models[model].predict(X_train)\n",
    "    validation_pred     = models[model].predict(X_validation)\n",
    "    train_prob          = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    validation_prob     = pd.DataFrame(models[model].predict_proba(X_validation))[1]\n",
    "    train_accuracy      = accuracy_score(y_train, train_pred)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_pred)\n",
    "    train_auc           = roc_auc_score(np.array(y_train),np.array(train_prob))\n",
    "    validation_auc      = roc_auc_score(np.array(y_validation),np.array(validation_prob))\n",
    "    train_f1            = f1_score(y_train, train_pred)\n",
    "    validation_f1       = f1_score(y_validation, validation_pred)\n",
    "    performances[model] = {\"Validation Accuracy\": validation_accuracy, \"Train Accuracy\": train_accuracy, \"Validation AUC\": validation_auc, \"Train AUC\": train_auc, \"Validation F1\": validation_f1, \"Train F1\": train_f1}\n",
    "pd.DataFrame(performances).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "GradientBoostingClassifier(max_depth=4, min_samples_split=1000,\n",
      "                           n_estimators=250)\n",
      "Wall time: 6min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {'min_samples_split':[1000, 10000], 'max_depth':[4,5,6], 'learning_rate':[0.009,0.1,0.5], 'n_estimators': [250, 500]}\n",
    "gs_gbc = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=3)\n",
    "gs_gbc.fit(X_train, y_train.values.ravel())\n",
    "print(gs_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.818696</td>\n",
       "      <td>0.908813</td>\n",
       "      <td>0.434277</td>\n",
       "      <td>0.795728</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Train AUC  Train Accuracy  Train F1  Validation AUC  \\\n",
       "GradientBoosting   0.818696        0.908813  0.434277        0.795728   \n",
       "\n",
       "                  Validation Accuracy  Validation F1  \n",
       "GradientBoosting                0.896           0.36  "
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting = GradientBoostingClassifier(max_depth=4, n_estimators = 250, learning_rate = 0.1, min_samples_split=1000)\n",
    "\n",
    "models = {\"GradientBoosting\" :boosting\n",
    "         }\n",
    "\n",
    "for model in models:\n",
    "    models[model].fit(X_train, y_train.values.ravel())\n",
    "performances = {}\n",
    "for model in models:\n",
    "    train_pred          = models[model].predict(X_train)\n",
    "    validation_pred     = models[model].predict(X_validation)\n",
    "    train_prob          = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    validation_prob     = pd.DataFrame(models[model].predict_proba(X_validation))[1]\n",
    "    train_accuracy      = accuracy_score(y_train, train_pred)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_pred)\n",
    "    train_auc           = roc_auc_score(np.array(y_train),np.array(train_prob))\n",
    "    validation_auc      = roc_auc_score(np.array(y_validation),np.array(validation_prob))\n",
    "    train_f1            = f1_score(y_train, train_pred)\n",
    "    validation_f1       = f1_score(y_validation, validation_pred)\n",
    "    performances[model] = {\"Validation Accuracy\": validation_accuracy, \"Train Accuracy\": train_accuracy, \"Validation AUC\": validation_auc, \"Train AUC\": train_auc, \"Validation F1\": validation_f1, \"Train F1\": train_f1}\n",
    "pd.DataFrame(performances).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "{'learning_rate': 0.2, 'max_depth': 2, 'min_samples_leaf': 50, 'min_samples_split': 500, 'n_estimators': 300}\n",
      "Wall time: 1h 15min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {'min_samples_split':[250, 500, 1000], 'max_depth':[2, 3,4,15], 'learning_rate':[0.1, 0.2, 0.5, 0.8], 'n_estimators': [200, 250, 300], 'min_samples_leaf' : [1, 5, 50]}\n",
    "gs_gbc = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=3)\n",
    "gs_gbc.fit(X_train, y_train.values.ravel())\n",
    "print(gs_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GradientBoosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.814093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.906188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.408822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation AUC</th>\n",
       "      <td>0.795015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.896750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.351648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GradientBoosting\n",
       "Train AUC                    0.814093\n",
       "Train Accuracy               0.906188\n",
       "Train F1                     0.408822\n",
       "Validation AUC               0.795015\n",
       "Validation Accuracy          0.896750\n",
       "Validation F1                0.351648"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting = GradientBoostingClassifier(max_depth=2, min_samples_leaf = 50, n_estimators = 300, learning_rate = 0.2, min_samples_split=500)\n",
    "\n",
    "models = {\"GradientBoosting\" :boosting\n",
    "         }\n",
    "\n",
    "for model in models:\n",
    "    models[model].fit(X_train, y_train.values.ravel())\n",
    "performances = {}\n",
    "for model in models:\n",
    "    train_pred          = models[model].predict(X_train)\n",
    "    validation_pred     = models[model].predict(X_validation)\n",
    "    train_prob          = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    validation_prob     = pd.DataFrame(models[model].predict_proba(X_validation))[1]\n",
    "    train_accuracy      = accuracy_score(y_train, train_pred)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_pred)\n",
    "    train_auc           = roc_auc_score(np.array(y_train),np.array(train_prob))\n",
    "    validation_auc      = roc_auc_score(np.array(y_validation),np.array(validation_prob))\n",
    "    train_f1            = f1_score(y_train, train_pred)\n",
    "    validation_f1       = f1_score(y_validation, validation_pred)\n",
    "    performances[model] = {\"Validation Accuracy\": validation_accuracy, \"Train Accuracy\": train_accuracy, \"Validation AUC\": validation_auc, \"Train AUC\": train_auc, \"Validation F1\": validation_f1, \"Train F1\": train_f1}\n",
    "pd.DataFrame(performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 8 (best performing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "{'learning_rate': 0.09, 'max_depth': 7, 'min_samples_leaf': 100, 'min_samples_split': 750, 'n_estimators': 250}\n",
      "Wall time: 2h 8min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {'min_samples_split':[500, 600, 750], 'max_depth':[2, 3, 4, 7], 'learning_rate':[0.09, 0.1, 0.2, 0.3], 'n_estimators': [250, 300, 350], 'min_samples_leaf' : [1, 5, 50, 100]}\n",
    "gs_gbc = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=3)\n",
    "gs_gbc.fit(X_train, y_train.values.ravel())\n",
    "print(gs_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GradientBoosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.821564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.906687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.411510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation AUC</th>\n",
       "      <td>0.796663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.899500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.371875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GradientBoosting\n",
       "Train AUC                    0.821564\n",
       "Train Accuracy               0.906687\n",
       "Train F1                     0.411510\n",
       "Validation AUC               0.796663\n",
       "Validation Accuracy          0.899500\n",
       "Validation F1                0.371875"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting = GradientBoostingClassifier(max_depth=7, min_samples_leaf = 100, n_estimators = 250, learning_rate = 0.09, min_samples_split=750)\n",
    "\n",
    "models = {\"GradientBoosting\" :boosting\n",
    "         }\n",
    "\n",
    "for model in models:\n",
    "    models[model].fit(X_train, y_train.values.ravel())\n",
    "performances = {}\n",
    "for model in models:\n",
    "    train_pred          = models[model].predict(X_train)\n",
    "    validation_pred     = models[model].predict(X_validation)\n",
    "    train_prob          = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    validation_prob     = pd.DataFrame(models[model].predict_proba(X_validation))[1]\n",
    "    train_accuracy      = accuracy_score(y_train, train_pred)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_pred)\n",
    "    train_auc           = roc_auc_score(np.array(y_train),np.array(train_prob))\n",
    "    validation_auc      = roc_auc_score(np.array(y_validation),np.array(validation_prob))\n",
    "    train_f1            = f1_score(y_train, train_pred)\n",
    "    validation_f1       = f1_score(y_validation, validation_pred)\n",
    "    performances[model] = {\"Validation Accuracy\": validation_accuracy, \"Train Accuracy\": train_accuracy, \"Validation AUC\": validation_auc, \"Train AUC\": train_auc, \"Validation F1\": validation_f1, \"Train F1\": train_f1}\n",
    "pd.DataFrame(performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "{'learning_rate': 0.09, 'max_depth': 7, 'min_samples_leaf': 50, 'min_samples_split': 750, 'n_estimators': 200}\n",
      "Wall time: 1h 46min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {'min_samples_split':[600, 750, 1000, 1200], 'max_depth':[2, 7, 9, 10], 'learning_rate':[0.08, 0.09, 0.1, 0.2], 'n_estimators': [200, 250, 1000], 'min_samples_leaf' : [50, 100, 200]}\n",
    "gs_gbc = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=3)\n",
    "gs_gbc.fit(X_train, y_train.values.ravel())\n",
    "print(gs_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GradientBoosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train AUC</th>\n",
       "      <td>0.796507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train Accuracy</th>\n",
       "      <td>0.903250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train F1</th>\n",
       "      <td>0.367647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation AUC</th>\n",
       "      <td>0.796851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <td>0.896750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation F1</th>\n",
       "      <td>0.328455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GradientBoosting\n",
       "Train AUC                    0.796507\n",
       "Train Accuracy               0.903250\n",
       "Train F1                     0.367647\n",
       "Validation AUC               0.796851\n",
       "Validation Accuracy          0.896750\n",
       "Validation F1                0.328455"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting = GradientBoostingClassifier(max_depth=3, min_samples_leaf = 2, n_estimators = 1000, learning_rate = 0.02, min_samples_split=8200, max_features = 'sqrt', subsample = 1, random_state = 1)\n",
    "\n",
    "#e 1000, lr 0.02, md 3, msl 2, mss 8200,   =  0.798324\n",
    "models = {\"GradientBoosting\" :boosting\n",
    "         }\n",
    "\n",
    "for model in models:\n",
    "    models[model].fit(X_train, y_train.values.ravel())\n",
    "performances = {}\n",
    "for model in models:\n",
    "    train_pred          = models[model].predict(X_train)\n",
    "    validation_pred     = models[model].predict(X_validation)\n",
    "    train_prob          = pd.DataFrame(models[model].predict_proba(X_train))[1]\n",
    "    validation_prob     = pd.DataFrame(models[model].predict_proba(X_validation))[1]\n",
    "    train_accuracy      = accuracy_score(y_train, train_pred)\n",
    "    validation_accuracy = accuracy_score(y_validation, validation_pred)\n",
    "    train_auc           = roc_auc_score(np.array(y_train),np.array(train_prob))\n",
    "    validation_auc      = roc_auc_score(np.array(y_validation),np.array(validation_prob))\n",
    "    train_f1            = f1_score(y_train, train_pred)\n",
    "    validation_f1       = f1_score(y_validation, validation_pred)\n",
    "    performances[model] = {\"Validation Accuracy\": validation_accuracy, \"Train Accuracy\": train_accuracy, \"Validation AUC\": validation_auc, \"Train AUC\": train_auc, \"Validation F1\": validation_f1, \"Train F1\": train_f1}\n",
    "pd.DataFrame(performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 210 candidates, totalling 1050 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}\n",
      "Wall time: 1h 23min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {'max_depth':[2,3,4,5,6],'learning_rate':[0.01, 0.02, 0.03,  0.09, 0.1, 0.2, 0.5], 'n_estimators': [250, 300, 500, 750, 900, 1000]}\n",
    "gs_gbc = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=1)\n",
    "gs_gbc.fit(X_full, y_full.values.ravel())\n",
    "print(gs_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980492969771998\n"
     ]
    }
   ],
   "source": [
    "print(gs_gbc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting = GradientBoostingClassifier(max_depth=3, n_estimators = 300, learning_rate = 0.1, random_state = 1).fit(X_full, y_full.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.818903661836298"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob = pd.DataFrame(boosting.predict_proba(X_full))[1]\n",
    "roc_auc_score(np.array(y_full),np.array(pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "{'learning_rate': 0.2, 'max_depth': 4, 'min_samples_leaf': 50, 'min_samples_split': 800, 'n_estimators': 250}\n",
      "Wall time: 15min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Grid search over Boosted Tree with 5 CV folds\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "parameters = {'min_samples_split':[600, 750, 800], 'max_depth':[ 4, 7], 'learning_rate':[0.09, 0.1, 0.2], 'n_estimators': [250, 300], 'min_samples_leaf' : [50, 100]}\n",
    "gs_gbc = GridSearchCV(model, parameters, scoring=\"roc_auc\", n_jobs=-1, cv=cv, verbose=3)\n",
    "gs_gbc.fit(X_full, y_full.values.ravel())\n",
    "print(gs_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7977706116368994\n"
     ]
    }
   ],
   "source": [
    "print(gs_gbc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting = GradientBoostingClassifier(max_depth=4, min_samples_leaf =  50, n_estimators = 250, learning_rate = 0.2, min_samples_split =  800, random_state = 1).fit(X_full, y_full.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8175038625835978"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob = pd.DataFrame(boosting.predict_proba(X_full))[1]\n",
    "roc_auc_score(np.array(y_full),np.array(pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model with best parameters on full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting = GradientBoostingClassifier(max_depth=7, min_samples_leaf = 100, n_estimators = 250, learning_rate = 0.09, min_samples_split=750).fit(X_full, y_full.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.818709883790546"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob = pd.DataFrame(boosting.predict_proba(X_full))[1]\n",
    "roc_auc_score(np.array(y_full),np.array(pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Interpreting Final model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Reference : https://ebookreading.net/view/book/EB9781787128576_44.html\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),('clf', boosting)])\n",
    "\n",
    "\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr,\n",
    "X=X_full, y=y_full.values.ravel(), cv=10, scoring = \"roc_auc\")\n",
    "\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='training AUC')\n",
    "\n",
    "\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='validation AUC')\n",
    "\n",
    "plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.65, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature Importance')"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Reference: https://towardsdatascience.com/understanding-feature-importance-and-how-to-implement-it-in-python-ff0287b20285\n",
    "\n",
    "#GB_fit = GB_best.fit(X_train, y_train)\n",
    "\n",
    "sort = boosting.feature_importances_.argsort()\n",
    "plt.barh(top_fs_vars[sort[::-1][:10][::-1]], boosting.feature_importances_[sort[::-1][:10][::-1]])\n",
    "plt.title(\"Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make prediction\n",
    "\n",
    "Use the best model to make prediction on test set. Submit the result to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob = pd.DataFrame(boosting.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob['client_id'] = test_id\n",
    "test_prob.rename(columns = {1:'subscribe'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission = test_prob[['client_id', 'subscribe']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>subscribe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2986</td>\n",
       "      <td>0.059781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29710</td>\n",
       "      <td>0.045494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38938</td>\n",
       "      <td>0.324450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31313</td>\n",
       "      <td>0.100829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24173</td>\n",
       "      <td>0.083929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>880</td>\n",
       "      <td>0.264805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>28072</td>\n",
       "      <td>0.144784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>40491</td>\n",
       "      <td>0.050267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5310</td>\n",
       "      <td>0.062245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6154</td>\n",
       "      <td>0.059781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      client_id  subscribe\n",
       "0          2986   0.059781\n",
       "1         29710   0.045494\n",
       "2         38938   0.324450\n",
       "3         31313   0.100829\n",
       "4         24173   0.083929\n",
       "...         ...        ...\n",
       "9995        880   0.264805\n",
       "9996      28072   0.144784\n",
       "9997      40491   0.050267\n",
       "9998       5310   0.062245\n",
       "9999       6154   0.059781\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission.to_csv(\"C:/Users/hhussain1/Desktop/SML/Group Project/Kaggle Uploads/submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
